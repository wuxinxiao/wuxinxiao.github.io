<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->  
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->  
<!--[if !IE]><!--> <html lang="en"> <!--<![endif]-->  
<head>
<title>Home Page of Dr.Wu</title>
<!-- Meta -->
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="">    
<link rel="shortcut icon" href="">  
<link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
<!-- Global CSS -->
<link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
<!-- Plugins CSS -->
<link rel="stylesheet" href="assets/plugins/font-awesome/css/font-awesome.css">
<link rel="stylesheet" href="assets/plugins/viewer.min.css">
<!-- Theme CSS -->  
<link id="theme-style" rel="stylesheet" href="assets/css/styles.css">

</head> 

<body>

<header class="header">
	<div class="top-bar container-fluid">
		<img id="viewer" class="background" alt="">
		<div class="actions">
			<a class="btn" href="index.html">中文主页</a>
		</div><!--//actions-->
	</div><!--//top-bar-->
	
	<div class="intro">
		<div class="container text-center">
			<img id="viewer" class="profile-image" src="assets/images/profile-image.jpg" alt="">
			<h1 class="name">Dr. Wu Xinxiao</h1>
			<div class="title">Full Professor</div>
			<div class="profile">
				<p align="justify">Xinxiao Wu received her Ph.D. from the school of computer science, Beijing Institute of Technology in July 2010. From August 2010 to October 2011, She worked as a Post-PhD student research fellow in Nanyang Technological University, Singapore. She joined the School of Computer Science, Beijing Institute of Technology in 2012. She is currently a Professor. She has obtained Excellent PhD studental Dissertation Award from the Chinese Association for Artificial Intelligence. She has published many papers in  top conferences and journals on computer vision and artificial intelligence: ICCV, CVPR, ECCV, AAAI, IJCAI, ACM MM, IJCV, IEEE TIP, IEEE TMM, IEEE TNNLS, IEEE TCSVT, IEEE TCYB. Her research work has been supported by many research grants as principal investigator, which includes the National Natural Science Foundation (NSFC), the Ministry of Education PhD studental Fund, and many school-enterprise projects, etc. She also servers on the editorial boards of IEEE Transactions on Multimedia. Her current research interests include machine learning, vision and language, multimedia video understanding. </p>
				<p align="justify" style="color: #FFFF55; font-weight: bold;font-size: 18px;">Welcome students who are interested in vision and language, machine learning and artificial intelligence to join us! </p>
			</div><!--//profile-->
		</div><!--//container-->
	</div><!--//intro-->
	
	<div class="contact-info">
		<div class="container text-center">
			<ul class="list-inline">
				<li class="email"><i class="fa fa-envelope"></i>wuxinxiao@bit.edu.cn</li>
				<li class="website"><i class="fa fa-globe"></i>wuxinxiao.github.io</li>
			</ul>
		</div><!--//container-->
	</div><!--//contact-info-->
	
	<div class="page-nav-space-holder hidden-xs">
		<div id="page-nav-wrapper" class="page-nav-wrapper text-center">
			<div class="container">
				<font size="+2">
					<ul id="page-nav" class="nav page-nav list-inline">
						<li><a class="scrollto" href="#ResearchInterests-section">Research Interests</a></li>
						<li><a class="scrollto" href="#SelectedPublications-section">Selected Publications</a></li>
						<li><a class="scrollto" href="#Group-section">Group</a></li>
						<li><a class="scrollto" href="#Eudcation-section">Teaching</a></li>
					</ul><!--//page-nav-->
				</font>
				
			</div>
		</div><!--//page-nav-wrapper-->
	</div>
	
</header><!--//header-->

<!-- 模态框（Modal） -->
<div class="modal fade" id="citeModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog modal-dialog-centered" role="document">
		<div class="modal-content">
			<div class="modal-body">
				<pre id="citeText">
				</pre>
			</div>
		</div><!-- /.modal-content -->
	</div><!-- /.modal-dialog -->
</div><!-- /.modal -->

<div class="wrapper container">
	<section id="News-section" class="contact-section section">
		<h2 class="section-title">News</h2>
		<div class="news-intro">
			<div class="dialog">
				<ul class="list-unstyled service-list" id="news-lists">
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2025-04-09</p> Yongqi Wang's paper “End-to-end Open-vocabulary Video Visual Relationship Detection using Multi-modal Prompting” was accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-12-17</p> Hongxi Li, Jun Chen, Zirui Shang, and Ziyi Wang won the Excellence Award at the 13th China Innovation and Entrepreneurship Competition and the 8th Emerging Fields Special Competition of Zhongguancun! Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-12-10</p> Zirui Shang, Yubo Zhu, and Hongxi Li's paper “Video Summarization using Denoising Diffusion Probabilistic Model” was accepted by The 39th AAAI Conference on Artificial Intelligence (AAAI2025). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-08-13</p> Rongjiang Zhu and Yuheng Shi's paper “大语言模型引导的开放域多标签动作识别” was accepted by《计算机研究与发展》. Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-02-13</p> Shuo Yang's paper “Dynamic Pathway for Query-Aware Feature Learning in Language-Driven Action Localization” was accepted by IEEE Transactions on Multimedia (TMM). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-01-23</p> Yuheng Shi and Hanxi Lin's paper “Commonsense Knowledge Prompting for Few-shot Action Recognition in Videos” was accepted by IEEE Transactions on Multimedia (TMM). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-07-26</p> Shuo Yang and Yongqi Wang's paper “Multi-modal Prompting for Open-vocabulary Video Visual Relationship Detection” was accepted by The 38th AAAI Conference on Artificial Intelligence (AAAI2024). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-07-26</p> Yayun Qi's paper “Relational Distant Supervision for Image Captioning without Image-text Pairs” was accepted by The 38th AAAI Conference on Artificial Intelligence (AAAI2024). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-07-26</p> Shuo Yang and Zirui Shang's paper “Probability Distribution Based Frame-supervised Language-driven Action Localization” was accepted by The 31st ACM International Conference on Multimedia (ACM MM2023). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-07-17</p> Wentian Zhao's paper “Boosting Entity-aware Image Captioning with Multi-modal Knowledge Graph” was accepted by IEEE Transactions on Multimedia (TMM). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-04-20</p> Shitong Shao and Huanran Chen's paper “Teaching What You Should Teach: A Data-Based Distillation Method” was accepted by International Joint Conference on Artificial Intelligence (IJCAI2023). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-03-29</p> Yubo Zhu's paper “Topic-aware Video Summarization using Multimodal Transformer” was accepted by Pattern Recognition (PR). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-03-17</p> Xiaofeng Ji's paper “Counterfactual Inference for Visual Relationship Detection in Videos” was accepted by IEEE International Conference on Multimedia and Expo (ICME2023). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-02-28</p> Jin Chen's paper “Meta-causal Learning for Single Domain Generalization” was accepted by The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR2023). Congratulations!</li>		
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-01-19</p> Wentian Zhao and Yayun Qi won the second prize of “Ingenuity Cup” National Artificial Intelligence Innovation Application Competition! Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-01-06</p> Tong Li's paper “Sentimental Visual Captioning using Multimodal Transformer” was accepted by International Journal of Computer Vision (IJCV). Congratulations!</li>		
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-12-05</p> Mengxiao Tian's paper “Adaptive Latent Graph Representation Learning for Image-Text Matchin” was accepted by IEEE Transactions on Image Processing (TIP). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-05-29</p> Wentian Zhao's paper “Learning Cooperative Neural Modules for Stylized Image Captioning” was accepted by International Journal of Computer Vision (IJCV). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-04-21</p> Shuo Yang's paper “Entity-Aware and Motion-Aware Transformers for Language-driven Action Localization” was accepted by International Joint Conference on Artificial Intelligence (IJCAI2022). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-03-07</p> Hanxi Lin's paper “Adaptive Recursive Circle Framework for Fing-grained Action Recognition” was accepted by IEEE International Conference on Multimedia and Expo (ICME2022). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-12-01</p> Jin Chen and Xiaofeng Ji's paper “Adaptive Image-to-video Scene Graph Generation via Knowledge Reasoning and Adversarial Learning” was accepted by 36th AAAI Conference on Artificial Intelligenc (AAAI2022). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-09-29</p> Wentian Zhao's paper “Multi-modal Dependency Tree for Video Captioning” was accepted by Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS2021). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-03-13</p> Jin Chen's paper “Sequential Instance Refinement for Cross-domain Object Detection in Images” was accepted by IEEE Transactions on Image Processin (TIP). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-03-12</p> Jingyi Hou and Yayun Qi's paper “跨语言知识蒸馏的视频中文字幕生成” was accepted by 《计算机学报》. Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-03-07</p> Tong Li's paper “Image Captioning with Inherent Sentiment”was accepted by IEEE International Conference on Multimedia and Expo (ICME2021 Oral). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-12-02</p> Jianwei Zhao and Ruiqi Wang's paper “Anticipating Future Relations via Graph Growing for Action Prediction” was accepted by 35th AAAI Conference on Artificial Intelligenc (AAAI2021). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-12-02</p> Jin Chen's paper “Spatial-temporal Causal Inference for Partial Image-to-video Adaptation” was accepted by 35th AAAI Conference on Artificial Intelligence (AAAI2021). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-11-24</p> Wentian Zhao's paper “Cross-domain Image Captioning via Cross-modal Retrieval and Model Adaptation” was accepted by IEEE Transactions on Image Processing (TIP). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-11-20</p> Ruiqi Wang's paper “Spatial-Temporal Relation Reasoning for Action Prediction in Videos” was accepted by International Journal of Computer Vision (IJCV). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true"></i> <p>2020-09-25</p> Jin Chen's paper "Domain Adversarial Reinforcement Learning for Partial Domain Adaptation" was accepted by IEEE Transactions on Neural Networks and Learning Systems (TNNLS). Congratulations!</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true"></i> <p>2020-07-26</p> Jialu Chen's paper "Preserving Global and Local Temporal Consistency for Arbitrary Video Style Transfer" was accepted by ACM Multimedia 2020. Congratulations!</li>
				</ul>
			</div><!--//diaplog-->
			<div style="text-align: center; margin-top: 2rem;">
				<a href="javascript:void(0)" id="load-more" onclick="loadMoreNews()">---- More News ----</a>
			</div>
		</div><!--//news-intro-->
	</section><!--//section-->

	<section id="ResearchInterests-section" class="contact-section section">
		<h2 class="section-title">Research Interests</h2>
		<div class="dialog" style="text-align:center">
			<td style="width: 199px; font-family: Helvetica,Arial,sans-serif;">
			<font size="+1" color="#00A7BE">
				<big><span style="font-weight: bold;">Artificial Intelligence</span></big>&nbsp;&nbsp;
				<span> visual captioning</span><br>&nbsp;
				video grounding&nbsp;&nbsp;
				<big style="font-weight: bold;">Computer Vision</big><br>&nbsp;
				<big><span style="font-weight: bold;">Vision+Language</span></big>&nbsp;&nbsp;
				<small>video style transfer</small><br>&nbsp;&nbsp;
				<small>animal interaction analysis</small>&nbsp;human action recognition<br>&nbsp;
				<span style="font-weight: bold;">domain adpatation</span>&nbsp;&nbsp; 
				<span style="font-weight: bold;">domain generalization</span><br>&nbsp;&nbsp;
				<small>video summarization &amp; visual storytelling</small> <br>&nbsp;
				<span style="font-weight: bold;">Multimedia Video Analysis and Undestanding</span><br>&nbsp;&nbsp;
				<small><big><span style="font-weight: bold;">Transfer Learning&nbsp;</span></big></small>&nbsp;
				<small> cross-domain object detection </small><br>
			</font>
          </td>
	</section><!--//section-->
	
	<section id="SelectedPublications-section" class="portfolio-section section">
		<h2 class="section-title">代表性论文</h2>
		<h3 style="text-align: center;font-size: 22px; color: #00BCD4; margin-top: 1.0rem; margin-bottom: 2.0rem;">Journal</h3>
		<div class="items-wrapper-journal isotope row" id="items-wrapper" style="height: auto;">
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer44" class="img-responsive" src="assets/images/portfolio/portfolio-44.jpg" data-original="assets/images/papers/paper44.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>End-to-end Open-vocabulary Video Visual Relationship Detection using Multi-modal Prompting.</a></h3>
						<div class="meta">Yongqi Wang, Xinxiao Wu, Shuo Yang, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025</div>
						<div class="link">
							<a href="assets/papers/2025/TPAMI_End_to_end_Open_vocabulary_Video_Visual_Relationship_Detection_using_Multi_modal_Prompting.pdf">[PDF]</a>
							<a href="https://github.com/wangyongqi558/EOV-MMP-VidVRD">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="44">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer43" class="img-responsive" src="assets/images/portfolio/portfolio-43.jpg" data-original="assets/images/papers/paper43.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Dynamic Pathway for Query-Aware Feature Learning in Language-Driven Action Localization.</a></h3>
						<div class="meta">Shuo Yang, Xinxiao Wu, Zirui Shang, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/TMM_Dynamic_Pathway_for_Query-Aware_Feature_Learning_in_Language-Driven_Action_Localization.pdf">[PDF]</a>
							<!-- <a href="https://github.com/OldStone0124/Knowledge-Prompting-for-FSAR">[CODE]</a> -->
							<a data-toggle="modal" data-target="#citeModal" data-whatever="43">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer41" class="img-responsive" src="assets/images/portfolio/portfolio-41.jpg" data-original="assets/images/papers/paper41.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Commonsense Knowledge Prompting for Few-shot Action Recognition in Videos.</a></h3>
						<div class="meta">Yuheng Shi, Xinxiao Wu, Hanxi Lin.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/TMM_Few-shot_Action_Recognition.pdf">[PDF]</a>
							<a href="https://github.com/OldStone0124/Knowledge-Prompting-for-FSAR">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="41">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer37" class="img-responsive" src="assets/images/portfolio/portfolio-37.jpg" data-original="assets/images/papers/paper37.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Boosting Entity-aware Image Captioning with Multi-modal Knowledge Graph.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/Boosting Entity-aware.pdf">[PDF]</a>
							<a href="https://github.com/wentian-zhao/entity-aware-caption/tree/main">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="37">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer36" class="img-responsive" src="assets/images/portfolio/portfolio-36.jpg" data-original="assets/images/papers/paper36.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Topic-aware Video Summarization using Multimodal Transformer.</a></h3>
						<div class="meta">Yubo Zhu, Wentian Zhao, Rui Hua, Xinxiao Wu.</div>
						<div class="action">Pattern Recognition (PR), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/Topic-aware video.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="36">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer39" class="img-responsive" src="assets/images/portfolio/portfolio-39.jpg" data-original="assets/images/papers/paper39.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Sentimental Visual Captioning using Multimodal Transformer.</a></h3>
						<div class="meta">Xinxiao Wu, Tong Li</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/IJCV2023-caption multimodal.pdf">[PDF]</a>
							<a href="https://github.com/ezeli/InSentiCap_ext">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="39">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer34" class="img-responsive" src="assets/images/portfolio/portfolio-34.jpg" data-original="assets/images/papers/paper34.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Adaptive Latent Graph Representation Learning for Image-Text Matching.</a></h3>
						<div class="meta">Mengxiao Tian, Xinxiao Wu, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2022</div>
						<div class="link">
							<a href="assets/papers/2022/ALGRL.pdf">[PDF]</a>
							<a href="https://github.com/Mengxiao-Tian/ALGR">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="34">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer33" class="img-responsive" src="assets/images/portfolio/portfolio-33.jpg" data-original="assets/images/papers/paper33.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Learning Cooperative Neural Modules for Stylized Image Captioning.</a></h3>
						<div class="meta">Xinxiao Wu, Wentian Zhao, Jiebo Luo</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/LCNM.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="33">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer28" class="img-responsive" src="assets/images/portfolio/portfolio-28.jpg" data-original="assets/images/papers/paper28.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Spatial–Temporal Relation Reasoning for Action Prediction in Videos.</a></h3>
						<div class="meta">Xinxiao Wu, Ruiqi Wang, Jingyi Hou, Hanxi Lin, Jiebo Luo.</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Spatial–Temporal Relation Reasoning.pdf">[PDF]</a>
							<a href="https://github.com/0HaNC/Graph-Action-Prediction">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="28">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer27" class="img-responsive" src="assets/images/portfolio/portfolio-27.jpg" data-original="assets/images/papers/paper27.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Sequential Instance Refinement for Cross-Domain Object Detection in Images.</a></h3>
						<div class="meta">Jin Chen, Xinxiao Wu, Lixin Duan, Lin Chen.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/SIR.pdf">[PDF]</a>
							<a href="https://github.com/ChenJinBIT/SIR">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="27">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer25" class="img-responsive" src="assets/images/portfolio/portfolio-25.jpg" data-original="assets/images/papers/paper25.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Captioning_via_Retrieval.pdf">[PDF]</a>
							<a href="https://github.com/enp7s0/cross-domain">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="25">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer22" class="img-responsive" src="assets/images/portfolio/portfolio-22.jpg" data-original="assets/images/papers/paper22.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Exploiting Informative Video Segments for Temporal Action Localization.</a></h3>
						<div class="meta">Che Sun, Hao Song, Xinxiao Wu, Yunde Jia, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/STAN.pdf">[PDF]</a>
							<a href="https://github.com/2120171054/Exploiting-Informative-Video-Segments-for-Temporal-Action-Localization">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="22">[BibTeX]</a>
						</div>						
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer21" class="img-responsive" src="assets/images/portfolio/portfolio-21.jpg" data-original="assets/images/papers/paper21.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Domain Adversarial Reinforcement Learning for Partial Domain Adaptation.</a></h3>
						<div class="meta">Jin Chen, Xinxiao Wu, Lixin Duan, Shenghua Gao.</div>
						<div class="action">IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/DARL.pdf">[PDF]</a>
							<a href="https://github.com/ChenJinBIT/DARL">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="21">[BibTeX]</a>
						</div>						
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer13" class="img-responsive" src="assets/images/portfolio/portfolio-13.jpg" data-original="assets/images/papers/paper13.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Confidence-guided self refinement for action prediction in untrimmed videos.</a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Ruiqi Wang, Jiebo Luo, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/SPR-Net.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="13">[BibTeX]</a>
						</div>							
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer14" class="img-responsive" src="assets/images/portfolio/portfolio-14.jpg" data-original="assets/images/papers/paper14.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Joint Learning of Multiple Latent Domains and Deep Representations for Domain Adaptation.</a></h3>
						<div class="meta">Xinxiao Wu, Jin Chen, Feiwu Yu, Mingyu Yao, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Cybernetics (T-CYB), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/Multiple_Latent_Domains_and_Deep_Representation.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="14">[BibTeX]</a>
						</div>						
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer15" class="img-responsive" src="assets/images/portfolio/portfolio-15.jpg" data-original="assets/images/papers/paper15.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Learning Normal Patterns via Adversarial Attention-Based Autoencoder for Abnormal Event Detection in Videos.</a></h3>
						<div class="meta">Hao Song, Che Sun, Xinxiao Wu, Mei Chen, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/Ada-Net.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="15">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer12" class="img-responsive" src="assets/images/portfolio/portfolio-12.jpg" data-original="assets/images/papers/paper12.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Exploiting Images for Video Recognition: Heterogeneous Feature Augmentation via Symmetric Adversarial Learning.</a></h3>
						<div class="meta">Feiwu Yu, Xinxiao Wu, Jialu Chen, Lixin Duan.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP),2019</div>
						<div class="link">
							<a href="assets/papers/2019/Sym-GAN.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="12">[BibTeX]</a>
						</div>  
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer11" class="img-responsive" src="assets/images/portfolio/portfolio-11.jpg" data-original="assets/images/papers/paper11.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Temporal Action Localization in Untrimmed Videos using Action Pattern Trees.</a></h3>
						<div class="meta">Hao Song, Xinxiao Wu, Bing Zhu, Yuwei Wu, Mei Chen, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2019</div>
						<div class="link">
							<a href="assets/papers/2019/Action_Pattern_Trees.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="11">[BibTeX]</a>
						</div> 
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer4" class="img-responsive" src="assets/images/portfolio/portfolio-4.jpg" data-original="assets/images/papers/paper4.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Extracting Key Segments of Videos for Event Detection by Learning From Web Sources.</a></h3>
						<div class="meta">Hao Song, Xinxiao Wu, Wennan Yu, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2018</div>
						<div class="link">
							<a href="assets/papers/2018/Extracting_Key_Segments.pdf">[PDF]</a>
							<a href="https://github.com/mcislab840832/Extracting-Key-Segments-of-Videos-for-Event-Detection">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="4">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer3" class="img-responsive" src="assets/images/portfolio/portfolio-3.jpg" data-original="assets/images/papers/paper3.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Content-Attention Representation by Factorized Action-Scene Network for Action Recognition. </a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Yuchao Sun, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2017</div>
						<div class="link">
							<a href="assets/papers/2018/FASNet.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="3">[BibTeX]</a>
						</div>
					</div><!--//content-->                  
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer5" class="img-responsive" src="assets/images/portfolio/portfolio-5.jpg" data-original="assets/images/papers/paper5.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>A Hierarchical Video Description for Complex Activity Understanding.</a></h3>
						<div class="meta">Cuiwei Liu, Xinxiao Wu, Yunde Jia.</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2016</div>
						<div class="link">
							<a href="assets/papers/2016/Hierarchical_Video_Description.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="5">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer10" class="img-responsive" src="assets/images/portfolio/portfolio-10.jpg" data-original="assets/images/papers/paper10.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Cross-View Action Recognition Over Heterogeneous Feature Spaces.</a></h3>
						<div class="meta">Xinxiao Wu, Han Wang, Cuiwei Liu, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2015</div>
						<div class="link">
							<a href="assets/papers/2015/HTDCC.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="10">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer9" class="img-responsive" src="assets/images/portfolio/portfolio-9.jpg" data-original="assets/images/papers/paper9.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Video Annotation via Image Groups from the Web. </a></h3>
						<div class="meta">Han Wang, Xinxiao Wu, and Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2014</div>
						<div class="link">
							<a href="assets/papers/2014/GDA.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="9">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->		
		</div><!-- item-wrapper-journal-->
		<div style="text-align: center;">
			<a href="javascript:void(0)" id="load-more-items" onclick="loadMoreJournalItems()">---- More Journal Article ----</a>
		</div><!--//item-wrapper-->
		<h3 style="text-align: center;font-size: 22px; color: #00BCD4; margin-top: 3.0rem; margin-bottom: 2.0rem;">Conference</h3>
		<div class="items-wrapper-paper isotope row" id="items-wrapper" style="height: auto;">
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer42" class="img-responsive" src="assets/images/portfolio/portfolio-42.jpg" data-original="assets/images/papers/paper42.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Relational Distant Supervision for Image Captioning without Image-text Pairs.</a></h3>
						<div class="meta">Yayun Qi, Wentian zhao, Xinxiao Wu.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/AAAI_2024_Relational_Distant_Supervision_for_Image_Captioning_without_Image-text_Pairs.pdf">[PDF]</a>
							<a href="https://github.com/MNOPQYY/Relational-distant-supervision-image-captioning">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="42">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer40" class="img-responsive" src="assets/images/portfolio/portfolio-40.jpg" data-original="assets/images/papers/paper40.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Multi-Modal Prompting for Open-Vocabulary Video Visual Relationship Detection.</a></h3>
						<div class="meta">Shuo Yang, Yongqi Wang, Xinxiao Wu.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/AAAI_2024_open_vocabulary_video_relationship_detection.pdf">[PDF]</a>
							<a href="https://github.com/wangyongqi558/MMP_OV_VidVRD">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="40">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer38" class="img-responsive" src="assets/images/portfolio/portfolio-38.jpg" data-original="assets/images/papers/paper38.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Probability Distribution Based Frame-supervised Language-driven Action Localization.</a></h3>
						<div class="meta">Shuo Yang, Zirui Shang, Xinxiao Wu.</div>
						<div class="action">The 31st ACM International Conference on Multimedia (ACM MM), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/MM2023-3653.pdf">[PDF]</a>
							<a href="https://github.com/shuoyang129/Distrbution-based-Frame-Supervised-LDAL">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="38">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer35" class="img-responsive" src="assets/images/portfolio/portfolio-35.jpg" data-original="assets/images/papers/paper35.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Meta-causal Learning for Single Domain Generalization.</a></h3>
						<div class="meta">Jin Chen, Zhi Gao, Xinxiao Wu, Jiebo Luo.</div>
						<div class="action">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/Meta-causal.pdf">[PDF]</a>
							<a href="https://github.com/zhigao2017/Meta-causal">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="35">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer32" class="img-responsive" src="assets/images/portfolio/portfolio-32.jpg" data-original="assets/images/papers/paper32.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Entity-aware and Motion-aware Transformers for Language-driven Action Localization in Videos.</a></h3>
						<div class="meta">Shuo Yang, Xinxiao Wu.</div>
						<div class="action">International Joint Conference on Artificial Intelligence (IJCAI), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/EAMAT.pdf">[PDF]</a>
							<a href="https://github.com/shuoyang129/EAMAT">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="32">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer31" class="img-responsive" src="assets/images/portfolio/portfolio-31.jpg" data-original="assets/images/papers/paper31.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Adaptive Recursive Circle Framework for Fing-grained Action Recognition.</a></h3>
						<div class="meta">Hanxi Lin, Wentian Zhao, Xinxiao Wu.</div>
						<div class="action">IEEE International Conference on Multimedia and Expo (ICME), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/ARC.pdf">[PDF]</a>
							<a href="https://github.com/0HaNC/ARC-ActionRecog/">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="31">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer30" class="img-responsive" src="assets/images/portfolio/portfolio-30.jpg" data-original="assets/images/papers/paper30.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Adaptive Image-to-video Scene Graph Generation via Knowledge Reasoning and Adversarial Learning.</a></h3>
						<div class="meta">Jin Chen, Xiaofeng Ji, Xinxiao Wu.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/I2VSGG.pdf">[PDF]</a>
							<a href="https://github.com/Ego-J/I2VSGG">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="30">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer29" class="img-responsive" src="assets/images/portfolio/portfolio-29.jpg" data-original="assets/images/papers/paper29.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Multi-modal Dependency Tree for Video Captioning.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu, Jiebo Luo.</div>
						<div class="action">Neural Information Processing Systems (NeurIPS), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Multi-modal Dependency Tree.pdf">[PDF]</a>
							<a href="https://github.com/wentian-zhao/tree_video_caption">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="29">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer26" class="img-responsive" src="assets/images/portfolio/portfolio-26.jpg" data-original="assets/images/papers/paper26.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Image Captioning with Inherent Sentiment.</a></h3>
						<div class="meta">Tong Li, Yunhui Hu, Xinxiao Wu.</div>
						<div class="action">IEEE International Conference on Multimedia and Expo (ICME) oral, 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/InSenti-Cap.pdf">[PDF]</a>
							<a href="https://github.com/ezeli/InSentiCap_model">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="26">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer24" class="img-responsive" src="assets/images/portfolio/portfolio-24.jpg" data-original="assets/images/papers/paper24.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Spatial-temporal Causal Inference for Partial Image-to-video Adaptation.</a></h3>
						<div class="meta">Jin Chen, Xinxiao Wu, Yao Hu, Jiebo Luo.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Spatial-temporal_Causal_Inference.pdf">[PDF]</a>
							<a href="https://github.com/ChenJinBIT/HPDA">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="24">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer23" class="img-responsive" src="assets/images/portfolio/portfolio-23.jpg" data-original="assets/images/papers/paper23.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Anticipating Future Relations via Graph Growing for Action Prediction.</a></h3>
						<div class="meta">Xinxiao Wu, Jianwei Zhao, Ruiqi Wang.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/LST-GCN.pdf">[PDF]</a>
							<a href="https://github.com/wuxinxiao/LST-GCN">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="23">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer16" class="img-responsive" src="assets/images/portfolio/portfolio-16.jpg" data-original="assets/images/papers/paper16.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Preserving Global and Local Temporal Consistency for Arbitrary Video Style Transfer.</a></h3>
						<div class="meta">Xinxiao Wu, Jialu Chen.</div>
						<div class="action">ACM International Conference on Multimedia (ACM MM), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/Preserving_Temporal_Consistency.pdf">[PDF]</a>
							<a href="https://github.com/mcislab-machine-learning/videostyletransfer">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="16">[BibTeX]</a>
						</div>	
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer6" class="img-responsive" src="assets/images/portfolio/portfolio-6.jpg" data-original="assets/images/papers/paper6.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Joint Commonsense and Relation Reasoning for Image and Video Captioning.</a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Xiaoxun Zhang, Yayun Qi, Yunde Jia, Jiebo Luo.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/C-R_reasoning.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="6">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer7" class="img-responsive" src="assets/images/portfolio/portfolio-7.jpg" data-original="assets/images/papers/paper7.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>MemCap: Memorizing Style Knowledge for Image Captioning.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu, Xiaoxun Zhang.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/MemCap.pdf">[PDF]</a>
							<a href="https://github.com/entalent/MemCap">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="7">[BibTeX]</a>
						</div>	
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer8" class="img-responsive" src="assets/images/portfolio/portfolio-8.jpg" data-original="assets/images/papers/paper8.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning.</h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Wentian Zhao, Jiebo Luo, Yunde Jia.</div>
						<div class="action">International Conference on Computer Vision (ICCV),2019</div>
						<div class="link">
							<a href="assets/papers/2019/Joint_Syntax_Representation_Learning_and_Visual_Cue_Translation.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="8">[BibTeX]</a>
						</div>
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer1" class="img-responsive" src="assets/images/portfolio/portfolio-1.jpg" data-original="assets/images/papers/paper1.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition.</a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Jin Chen, Jiebo Luo, Yunde Jia</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2018</div> 
						<div class="link">
							<a href="assets/papers/2018/Unsupervised_Mid-Level_Video_Representation.pdf">[PDF]</a>
							<a href="https://github.com/mcislab840832/Mid-Level-video-representation-for-action-recognition">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="1">[BibTeX]</a>
						</div>
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer2" class="img-responsive" src="assets/images/portfolio/portfolio-2.jpg" data-original="assets/images/papers/paper2.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks.</a></h3>
						<div class="meta">Feiwu Yu, Xinxiao Wu, Yuchao Sun, Lixin Duan.</div>
						<div class="action">International Joint Conference on Artificial Intelligence (IJCAI), 2018</div>
						<div class="link">
							<a href="assets/papers/2018/HiGAN.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="2">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer17" class="img-responsive" src="assets/images/portfolio/portfolio-17.jpg" data-original="assets/images/papers/paper17.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Cross-View Action Recognition over Heterogeneous Feature Spaces.</a></h3>
						<div class="meta">Xinxiao Wu, Han Wang, Cuiwei Liu, Yunde Jia.</div>
						<div class="action">IEEE International Conference on Computer Vision (ICCV), 2013</div>
						<div class="link">
							<a href="assets/papers/2013/HTDCC.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="17">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer18" class="img-responsive" src="assets/images/portfolio/portfolio-18.jpg" data-original="assets/images/papers/paper18.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>View-Invariant Action Recognition Using Latent Kernelized Structural SVM.</a></h3>
						<div class="meta">Xinxiao Wu, Yunde Jia.</div>
						<div class="action">European Conference on Computer Vision (ECCV), 2012</div>
						<div class="link">
							<a href="assets/papers/2012/Latent_Kernelized_Structural_SVM.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="18">[BibTeX]</a>
						</div>	
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/portfolio/portfolio-19.jpg" data-original="assets/images/papers/paper19.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Action recognition using context and appearance distribution features.</a></h3>
						<div class="meta">Xinxiao Wu, Dong Xu, Lixin Duan, Jiebo Luo.</div>
						<div class="action">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011</div>
						<div class="link">
							<a href="assets/papers/2011/AFMKL.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="19">[BibTeX]</a>
						</div>	
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/portfolio/portfolio-20.jpg" data-original="assets/images/papers/paper20.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Incremental discriminative-analysis of canonical correlations for action recognition.</a></h3>
						<div class="meta">Xinxiao Wu, Wei Liang, Yunde Jia.</div>
						<div class="action">IEEE International Conference on Computer Vision (ICCV), 2009</div>	
						<div class="link">
							<a href="assets/papers/2011/IDCC.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="20">[BibTeX]</a>
						</div>	
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//item-wrapper-->
		
		<div style="text-align: center;">
			<a href="javascript:void(0)" id="load-more-items" onclick="loadMorePaperItems()">---- More Conference Paper ----</a>
		</div>
		
	</section><!--//section-->

	<section id="Group-section" class="group-section section">
		<h2 class="section-title">Group</h2>
		<div class="items-wrapper isotope row">
			<div class="item frontend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer13" class="img-responsive" src="assets/images/group/tianmengxiao.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Tian Mengxiao</a></h3>
						<div class="meta">PhD student</div>
						<div class="action">video understanding</a></div>
					</div><!--//content-->                  
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer14" class="img-responsive" src="assets/images/group/qiyayun.jpg" data-original="assets/images/papers/paper7.jpg" alt="" style="border-radius: 70%" />
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Qi Yayun</a></h3>
						<div class="meta">phD student</div>
						<div class="action">video caption</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer18" class="img-responsive" src="assets/images/group/chenjun.jpg" alt="" style="border-radius: 70%" />
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Chen Jun</a></h3>
						<div class="meta">phD student</div>
						<div class="action">incremental learning</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/group/shangzirui.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Shang Zirui</a></h3>
						<div class="meta">phD student</div>
						<div class="action">video grounding</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row1-->
		<div class="row">
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/group/songyiqi.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Song Yiqi</a></h3>
						<div class="meta">phD student</div>
						<div class="action">multimodal reasoning</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/group/lihongxi.jpeg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Li Hongxi</a></h3>
						<div class="meta">MS student</div>
						<div class="action">video summarization</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/group/huangxiqing.jpeg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Huang Xiqing</a></h3>
						<div class="meta">MS student</div>
						<div class="action">action segmentation</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/group/wangyongqi.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Wang Yongqi</a></h3>
						<div class="meta">MS student</div>
						<div class="action">video relation detection</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div>	<!--//row2-->		
		<div class="row">
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/group/wangziyi.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Wang Ziyi</a></h3>
						<div class="meta">MS student</div>
						<div class="action">domain generalization</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer21" class="img-responsive" src="assets/images/group/zhurongjiang.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Zhu Rongjiang</a></h3>
						<div class="meta">MS student</div>
						<div class="action">video action recognition</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer21" class="img-responsive" src="assets/images/group/tanyunteng.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">Tan Yunteng</a></h3>
						<div class="meta">MS student</div>
						<div class="action">LLM-based agents</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
		</div><!--//row3-->	
	</section><!--//section-->
	
	<section id="Group-section" class="education-section section">
		<h2 class="section-title-2">Alumni</h2>
		<h3  style="text-align: center;font-size: 20px; color: #00BCD4; margin-top: 1.7rem;">—— phD graduates ——</h2>	
		<div class="row">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Yang Shuo</h3>
					<div class="education-body">Shenzhen MSU-BIT University Associate Professor</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Chen Jin</h3>
					<div class="education-body">Aerospace Intelligence Research Institute R&D Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Zhao Wentian</h3>
					<div class="education-body">Beijing Institute of Technology PostPhD</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!-- //row1 -->
		<div class="row">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Wang Han</h3>
					<div class="education-body">Beijing Forestry University
						Associate Professor</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Song Hao</h3>
					<div class="education-body">Tencent
						Researcher</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Hou Jingyi</h3>
					<div class="education-body">Beijing University of Science and Technology
						PostPhD studental Teaching Fellow</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row2-->
		<h3  style="text-align: center; font-size: 20px; color: #00BCD4;">—— MS graduates ——</h3>
		
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Zhu Yubo</h3>
					<div class="education-body">Aerospace Information Research Institute Assistant engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Shi Yuheng</h3>
					<div class="education-body">Bank of China Information management Pearson</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Wen Zihan</h3>
					<div class="education-body">China Academy of Space Technology Algorithm Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
		</div> <!--//row3-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Ji Xiaofeng</h3>
					<div class="education-body">ByteDance Algorithm Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Yi Jiacheng</h3>
					<div class="education-body">The PLA Strategic Support Force Assistant engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Li Tong</h3>
					<div class="education-body">Alibaba Algorithm Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row4-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Lin Hanxi</h3>
					<div class="education-body">ByteDance Algorithm Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Liu Chao</h3>
					<div class="education-body">Alibaba
						Senior Algorithm Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Yu Feiwu</h3>
					<div class="education-body">Alibaba DAMO
						Development Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row5-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Zhu Bing</h3>
					<div class="education-body">Alibaba Cloud
						Data Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Sun Yuchao</h3>
					<div class="education-body">Beijing Megvii Co., Ltd
						Algorithm Researcher</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Wang Ruiqi</h3>
					<div class="education-body">MI
						Product Manager</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row6-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Hua Rui</h3>
					<div class="education-body">AVIC Manufacturing Technology Institute
						Information Management</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Chen Jialu</h3>
					<div class="education-body">MI
						Algorithm Engineer</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Li Tianyu</h3>
					<div class="education-body">Beijing Infrastructure Investment
						Management Trainee</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row7-->	
		<div style="text-align: center;">
			<a href="javascript:void(0)" id="load-more-group" onclick="loadMoreGroup()">---- More Alumni ----</a>
		</div>	
	</section><!--//section-->

	<section id="Eudcation-section" class="education-section section">
		<h2 class="section-title-2">Teaching</h2>
		<div class="row">
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Compiler Principle and Design</h3>
					<div class="education-body">
						For Undergraduate students
					</div><!--//education-body-->
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Artificial Intelligence</h3>
					<div class="education-body">
						For Undergraduate students
					</div><!--//education-body-->
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Image and Video Processing</h3>
					<div class="education-body">
						For MS students
					</div><!--//education-body-->
					<!-- <div class="time">Fall semester</div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.3 Morphological Filtering for Image Enhancement and Detection.pptx">3.3 Morphological Filtering for Image Enhancement and Detection</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.4 Wavelet Denoising for Image Enhancement.pptx">3.4 Wavelet Denoising for Image Enhancement</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.5 Basic Methods for Image Restoration and Identification.pptx">3.5 Basic Methods for Image Restoration and Identification</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.10 Motion Detection and Estimation.pptx">3.10 Motion Detection and Estimation</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.11 Video Enhancement and Restoration.pptx">3.11 Video Enhancement and Restoration</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/Handbook of Image and Video Processing_Reference.pdf">Handbook of Image and Video Processing_Reference</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/Image Compression.pptx">Image Compression</a></div> -->
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">Computational Perception</h3>
					<div class="education-body">
						For Ph.D students
					</div><!--//education-body-->
					<!-- <div class="time">Fall semester</div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture1-Human Activity Analysis.rar">Lecture1-Human Activity Analysis</a></div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture2-object recognition.rar">Lecture2-object recognition</a></div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture3-Transfer Learning.rar">Lecture3-Transfer Learning</a></div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture4-Vision and Language.pptx">Lecture4-Vision and Language</a></div> -->
				</div><!--//item-inner-->
			</div><!--//item-->			
		</div><!--//row-->
	</section><!--//section-->

	
</div><!--//wrapper-->

<footer class="footer text-center">
	<div class="container">
		<p>Media Computing and Intelligent Systems Lab</p>
		<small class="copyright">Beijing Institute of Technology Copyright Address: 5 South Zhongguancun Street, Haidian District, Beijing, China 100081 </small>
	</div><!--//container-->
</footer>

<!-- Javascript -->          
<script type="text/javascript" src="assets/plugins/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>  
<script type="text/javascript" src="assets/plugins/back-to-top.js"></script>
<script type="text/javascript" src="assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script> 
<script type="text/javascript" src="assets/plugins/easy-pie-chart/dist/jquery.easypiechart.min.js"></script>
<script type="text/javascript" src="assets/plugins/imagesloaded.pkgd.min.js"></script> 
<script type="text/javascript" src="assets/plugins/isotope.pkgd.min.js"></script>  
<script type="text/javascript" src="assets/plugins/viewer.min.js"></script>

<!-- custom js -->
<script type="text/javascript" src="assets/js/main.js"></script>

<!-- Style Switcher (REMOVE ON YOUR PRODUCTION SITE) -->
<script src="assets/js/demo/style-switcher.js"></script>

<script>
	// 新闻显示
    let newsItems = document.querySelectorAll('.news-item');
    let visibleCount = 10;  // Initially show 10 items

    // Function to display only the first 10 news items
    function loadNews() {
        newsItems.forEach((item, index) => {
            if (index < visibleCount) {
                item.style.display = 'list-item';
            } else {
                item.style.display = 'none';
            }
        });
    }

    // Function to load more news items
    function loadMoreNews() {
        visibleCount += 10;  // Increase the visible count by 10
        loadNews();
    }

    // Load initial news
    loadNews();
</script>


<script>
	// 代表性期刊文章显示
	// items-wrapper 
    let journalItems = document.querySelectorAll('.portfolio-section .items-wrapper-journal .item');
    let visibleCountJournalItems = 5;  // Initially show 5 items

    // Function to display the first set of items
    function loadJournalItems() {
        journalItems.forEach((item, index) => {
            if (index < visibleCountJournalItems) {
                item.style.display = 'block'; // Show the item
            } else {
                item.style.display = 'none'; // Hide the item
            }
        });
    }

    // Function to load more items
    function loadMoreJournalItems() {
        visibleCountJournalItems += 5;  // Show 3 more items each time
        loadJournalItems();

		// Update isotope layout after adding more items
		let grid = document.querySelector('.portfolio-section .items-wrapper-journal');
    	$(grid).isotope('layout');  // 调用 Isotope 的布局更新
    }

    // Load initial items
    loadJournalItems();
</script>


<script>
	// 代表性会议论文显示
	// items-wrapper 
    let items = document.querySelectorAll('.portfolio-section .items-wrapper-paper .item');
    let visibleCountItems = 5;  // Initially show 5 items

    // Function to display the first set of items
    function loadItems() {
        items.forEach((item, index) => {
            if (index < visibleCountItems) {
                item.style.display = 'block'; // Show the item
            } else {
                item.style.display = 'none'; // Hide the item
            }
        });
    }

    // Function to load more items
    function loadMorePaperItems() {
        visibleCountItems += 5;  // Show 3 more items each time
        loadItems();

		// Update isotope layout after adding more items
		let grid = document.querySelector('.portfolio-section .items-wrapper-paper');
    	$(grid).isotope('layout');  // 调用 Isotope 的布局更新
    }

    // Load initial items
    loadItems();
</script>


<script>
	// 毕业生显示
	// items-wrapper 
    let groupItems = document.querySelectorAll('.ms-item');
    let visibleCountGroup = 1;  // Initially show 1 ms group row

    // Function to display the first set of items
    function loadGroup() {
        groupItems.forEach((groupItem, index) => {
            if (index < visibleCountGroup) {
                groupItem.style.display = 'block'; // Show the item
            } else {
                groupItem.style.display = 'none'; // Hide the item
            }
        });
    }

    // Function to load more items
    function loadMoreGroup() {
        visibleCountGroup += 2;  // Show 3 more items each time
        loadGroup();

		// Update isotope layout after adding more items
		// let grid = document.querySelector('.portfolio-section .items-wrapper');
    	// $(grid).isotope('layout');  // 调用 Isotope 的布局更新
    }

    // Load initial items
    loadGroup();
</script>



</body>
</html>