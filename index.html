<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->  
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->  
<!--[if !IE]><!--> <html lang="en"> <!--<![endif]-->  
<head>
<title>吴心筱个人主页</title>
<!-- Meta -->
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="">    
<link rel="shortcut icon" href="">  
<link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
<!-- Global CSS -->
<link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
<!-- Plugins CSS -->
<link rel="stylesheet" href="assets/plugins/font-awesome/css/font-awesome.css">
<link rel="stylesheet" href="assets/plugins/viewer.min.css">
<!-- Theme CSS -->  
<link id="theme-style" rel="stylesheet" href="assets/css/styles.css">

</head> 

<body>

<header class="header">
	<div class="top-bar container-fluid">
		<div class="actions">
			<a class="btn" href="indexEn.html">Translate to English</a>
		</div><!--//actions-->
	</div><!--//top-bar-->
	
	<div class="intro">
		<div class="container text-center">
			<img class="profile-image" src="assets/images/profile-image.png" alt="">
			<h1 class="name">吴心筱</h1>
			<div class="title">博士 副教授 博士生导师</div>
			<div class="profile">
				<p align="justify">北京理工大学计算机学院教师。2010年7月在北京理工大学获得计算机应用技术工学博士学位，并获得北京理工大学优秀博士学位论文奖。2010年至2011年赴新加坡南洋理工大学计算机学院从事博士后研究。2011年12月加入北京理工大学计算机学院。2012年获得全国人工智能学会优秀博士学位论文奖。2013年入选校级优秀青年教师资助计划。在计算机视觉与人工智能顶级国际会议ICCV, CVPR, AAAI, IJCAI以及SCI收录国际重要学术期刊IJCV, IEEE TIP, IEEE TMM, IEEE TCSVT, IEEE TCYB上发表多篇论文。负责国家自然科学基金，教育部博士点基金等多项科研项目。主要从事机器学习、计算机视觉、图像视频内容理解方向的研究。 </p>
			</div><!--//profile-->
		</div><!--//container-->
	</div><!--//intro-->
	
	<div class="contact-info">
		<div class="container text-center">
			<ul class="list-inline">
				<li class="email"><i class="fa fa-envelope"></i>wuxinxiao@bit.edu.cn</li>
				<li class="email"><i class="fa fa-envelope"></i>wuxinxiao@gmail.com</li>
				<li class="website"><i class="fa fa-globe"></i>wuxinxiao.github.io</li>
			</ul>
		</div><!--//container-->
	</div><!--//contact-info-->
	
	<div class="page-nav-space-holder hidden-xs">
		<div id="page-nav-wrapper" class="page-nav-wrapper text-center">
			<div class="container">
				<ul id="page-nav" class="nav page-nav list-inline">
					<li><a class="scrollto" href="#ResearchInterests-section">研究方向</a></li>
					<li><a class="scrollto" href="#SelectedPublications-section">经典论文</a></li>
					<li><a class="scrollto" href="#Publications-section">所有论文</a></li>
					<li><a class="scrollto" href="#Eudcation-section">教学内容</a></li>
					<li><a class="scrollto" href="#Project-section">科研项目</a></li>
				</ul><!--//page-nav-->
			</div>
		</div><!--//page-nav-wrapper-->
	</div>
	
</header><!--//header-->

<div class="wrapper container">
	<section id="ResearchInterests-section" class="contact-section section">
		<h2 class="section-title">研究方向</h2>
		<div class="intro">
			<img class="profile-image" src="assets/images/logo.png" alt="">
			<div class="dialog">
				<ul class="list-unstyled service-list">
					<li><i class="fa fa-check" aria-hidden="true"></i> 图像/视频内容理解与语义描述</li>
					<li><i class="fa fa-check" aria-hidden="true"></i> 图像/视频中行为识别与事件检测</li>
					<li><i class="fa fa-check" aria-hidden="true"></i> 深度学习及其应用</li>
					<li><i class="fa fa-check" aria-hidden="true"></i> 迁移学习及其应用</li>
					<li><i class="fa fa-check" aria-hidden="true"></i> 强化学习及其应用</li>
				</ul>
			</div><!--//diaplog-->
		</div><!--//intro-->
	</section><!--//section-->

	<section id="SelectedPublications-section" class="portfolio-section section">
		<h2 class="section-title">经典论文</h2>
		<div class="items-wrapper isotope row">
			<div class="item frontend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer1" class="img-responsive" src="assets/images/portfolio/portfolio-1.jpg" data-original="assets/images/papers/paper1.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition.</h3>
						<div class="meta">J.Hou, X.Wu, J.Chen, J.Luo, Y.Jia</div>
						<div class="action">AAAI,2018</a></div>
						<a class="link-mask" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16794/16277"></a>  
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->

			<div class="item backend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer2" class="img-responsive" src="assets/images/portfolio/portfolio-2.jpg" data-original="assets/images/papers/paper2.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks.</a></h3>
						<div class="meta">F.Yu, X.Wu, Y.Sun, <br>L.Duan.  </div>
						<div class="action">IJCAI,2018</a></div>
						<a class="link-mask" href="https://arxiv.org/pdf/1805.04384.pdf"></a>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item backend frontend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer3" class="img-responsive" src="assets/images/portfolio/portfolio-3.jpg" data-original="assets/images/papers/paper3.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Content-Attention Representation by Factorized Action-Scene Network for Action Recognition. </a></h3>
						<div class="meta">J.Hou, X.Wu, Y.Sun, Y.Jia.</div>
						<div class="action">IEEE TMM,2018</a></div>
						<a class="link-mask" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8101020"></a>
					</div><!--//content-->                  
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item frontend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer4" class="img-responsive" src="assets/images/portfolio/portfolio-4.jpg" data-original="assets/images/papers/paper4.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Extracting Key Segments of Videos for Event Detection by Learning From Web Sources.</a></h3>
						<div class="meta">H.Song, X.Wu, W.Yu, <br>Y.Jia.</div>
						<div class="action">IEEE TMM,2018</a></div>
						<a class="link-mask" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8068288"></a>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item 左下三-->
			<div class="item backend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer7" class="img-responsive" src="assets/images/portfolio/portfolio-5.jpg" data-original="assets/images/papers/paper7.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Cross-View Action Recognition Over Heterogeneous Feature Spaces.</a></h3>
						<div class="meta"> X.Wu, H.Wang, C.Liu, Y.Jia.</div>
						<div class="action">IEEE TIP,2015</a></div>
						<a class="link-mask" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7122882"></a>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div>

			<!--//item 左下一-->
			<div class="item backend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer5" class="img-responsive" src="assets/images/portfolio/portfolio-6.jpg" data-original="assets/images/papers/paper5.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">A Hierarchical Video Description for Complex Activity Understanding.</a></h3>
						<div class="meta">C.Liu, X.Wu,Y.Jia.<br> &nbsp </div>
						<div class="action">IJCV,2016</a></div>
						<a class="link-mask" href="https://link.springer.com/content/pdf/10.1007%2Fs11263-016-0897-2.pdf"></a>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			

			<!--左下2-->
			<div class="item frontend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer6" class="img-responsive" src="assets/images/portfolio/portfolio-7.jpg" data-original="assets/images/papers/paper6.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Transfer Latent SVM for Joint Recognition and Localization of Actions in Videos.</a></h3>
						<div class="meta">C.Liu, X.Wu, Y.Jia. </div>
						<div class="action">IEEE TCYB，2016</a></div>
						<a class="link-mask" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7299283"></a>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			

			<!--左下4-->
			<div class="item frontend backend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer8" class="img-responsive" src="assets/images/portfolio/portfolio-8.jpg" data-original="assets/images/papers/paper8.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title">Cross-view action recognition over heterogeneous feature spaces.</a></h3>
						<div class="meta">X.Wu, H.Wang，Y.Jia.</div>
						<div class="action">ICCV 2013</a></div>
						<a class="link-mask" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7122882"></a>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->			
		</div><!--//item-wrapper-->
		
	</section><!--//section-->

	<section id="Publications-section" class="testimonials-section section">
		<h2 class="section-title">所有论文</h2>
		
		<div id="testimonials-carousel" class="testimonials-carousel carousel slide" data-interval="8000">
			
			<!-- Indicators -->
			<ol class="carousel-indicators">
				<li data-target="#testimonials-carousel" data-slide-to="0" class="active"></li>
				<li data-target="#testimonials-carousel" data-slide-to="1"></li>
				<li data-target="#testimonials-carousel" data-slide-to="2"></li>
				<li data-target="#testimonials-carousel" data-slide-to="3"></li>
				<li data-target="#testimonials-carousel" data-slide-to="4"></li>
				<li data-target="#testimonials-carousel" data-slide-to="5"></li>
				<li data-target="#testimonials-carousel" data-slide-to="6"></li>
				<li data-target="#testimonials-carousel" data-slide-to="7"></li>
			</ol>
			
			<!-- Wrapper for slides -->
			<div class="carousel-inner">
				<div class="item active"><!--//2018-->
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            					
						<div class="source">
						    <div class="papername"><a href="https://reader.elsevier.com/reader/sd/DC843858ACB56811DEFF4C739DE0DB763549E580036597CB70DC52B96D76B338867CE33335A83C6AE079FE502658B135">Action recognition with motion map 3D network.</a></div>
							<div class="name">Yuchao Sun, Xinxiao Wu, Wennan Yu, Feiwu Yu.</div>
							<div class="position">Neurocomputing, 2018.</div>
						</div><!--//source--> 
					</blockquote>
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8068288">Extracting Key Segments of Videos for Event Detection by Learning From Web Sources.</a></div>
							<div class="name">Hao Song, Xinxiao Wu, Wennan Yu, Yunde Jia.</div>
							<div class="position">IEEE TMM, 2018.</div>
						</div><!--//source-->      
					</blockquote>  
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8101020">Content-Attention Representation by Factorized Action-Scene Network for Action Recognition.</a></div>
							<div class="name">Jingyi Hou, Xinxiao Wu, Yuchao Sun, Yunde Jia.</div>
							<div class="position">IEEE TMM, 2018.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16794/16277">Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition.</a></div>
							<div class="name">Jingyi Hou, Xinxiao Wu, Jin Chen, Jiebo Luo, Yunde Jia.</div>
							<div class="position">AAAI, 2018.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://arxiv.org/pdf/1805.04384.pdf">Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks.</a></div>
							<div class="name">Feiwu Yu, Xinxiao Wu, Yuchao Sun, Lixin Duan.</div>
							<div class="position">IJCAI, 2018.</div>
						</div><!--//source-->      
					</blockquote> 
				</div>

				<!--//item2017-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            					
						<div class="source">
						    <div class="papername"><a href="http://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2016.0148">Heterogeneous domain adaptation method for video annotation.</a></div>
							<div class="name">Han Wang, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">IET Computer Vision, 2017.</div>
						</div><!--//source--> 
					</blockquote>
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/article/10.1007%2Fs11042-016-3253-1">Recognizing key segments of videos for video annotation by learning from web image sets.</a></div>
							<div class="name">Hao Song, Xinxiao Wu, Wei Liang, Yunde Jia.</div>
							<div class="position">Multimedia Tools Appl, 2017.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/chapter/10.1007%2F978-3-319-71607-7_51">Heterogeneous Multi-group Adaptation for Event Recognition in Consumer Videos.</a></div>
							<div class="name">Mingyu Yao, Xinxiao Wu, Mei Chen, Yunde Jia.</div>
							<div class="position">ICIG, 2017.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8101020">Representing Discrimination of Video by a Motion Map.</a></div>
							<div class="name">Wennan Yu, Yuchao Sun, Feiwu Yu, Xinxiao Wu.</div>
							<div class="position">PCM, 2017.</div>
						</div><!--//source-->      
					</blockquote>   		   
				</div>

				<!--//item2016-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="http://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2014.0405">Multi-group-multi-class domain adaptation for event recognition.</a></div>
							<div class="name">Yang Feng, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">IET Computer Vision, 2016.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/article/10.1007%2Fs11263-016-0897-2">A Hierarchical Video Description for Complex Activity Understanding.</a></div>
							<div class="name">Cuiwei Liu, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">IJCV, 2016.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ac.els-cdn.com/S0925231216001417/1-s2.0-S0925231216001417-main.pdf?_tid=6bd61052-3859-4eb1-b9d2-404e264946f3&acdnat=1530426015_43ed3ce500bba82bc144c9a40bc96f83">Heterogeneous discriminant analysis for cross-view action recognition.</a></div>
							<div class="name">Wanchen Sui, Xinxiao Wu, Yang Feng, Yunde Jia.</div>
							<div class="position">Neurocomputing, 2016.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7299283">Transfer Latent SVM for Joint Recognition and Localization of Actions in Videos.</a></div>
							<div class="name">Cuiwei Liu, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">IEEE Trans. Cybernetics, 2016.</div>
						</div><!--//source-->      
					</blockquote>
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7552981">Multimedia event detection via deep spatial-temporal neural networks.</a></div>
							<div class="name">Jingyi Hou, Xinxiao Wu, Feiwu Yu, Yunde Jia.</div>
							<div class="position">ICME, 2016.</div>
						</div><!--//source-->      
					</blockquote>               
				</div>

				<!--//item2015-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/article/10.1007%2Fs11042-014-2175-z">Cross-domain structural model for video event annotation via web images.</a></div>
							<div class="name">Han Wang, Xiabi Liu, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">Multimedia Tools Appl, 2015.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7122882">Cross-View Action Recognition Over Heterogeneous Feature Spaces.</a></div>
							<div class="name">Xinxiao Wu, Han Wang, Cuiwei Liu, Yunde Jia.</div>
							<div class="position">IEEE TIP, 2015.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7395806">Incremental Discriminant Learning for Heterogeneous Domain Adaptation.</a></div>
							<div class="name">Peng Han, Xinxiao Wu.</div>
							<div class="position">ICDM Workshops, 2015.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7395807">Finding Event Videos via Image Search Engine.</a></div>
							<div class="name">Han Wang, Xinxiao Wu.</div>
							<div class="position">ICDM Workshops, 2015.</div>
						</div><!--//source-->      
					</blockquote>
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/chapter/10.1007%2F978-3-319-21978-3_16">A Multiple Image Group Adaptation Approach for Event Recognition in Consumer Videos.</a></div>
							<div class="name">Dengfeng Zhang, Wei Liang, Hao Song, Zhen Dong, Xinxiao Wu.</div>
							<div class="position">ICIG, 2015.</div>
						</div><!--//source-->      
					</blockquote>  
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/chapter/10.1007%2F978-3-319-26561-2_67">Heterogeneous Discriminant Analysis for Cross-View Action Recognition.</a></div>
							<div class="name">Wanchen Sui, Xinxiao Wu, Yang Feng, Wei Liang, Yunde Jia.</div>
							<div class="position">ICONIP, 2015.</div>
						</div><!--//source-->      
					</blockquote>               
				</div><!--//item-->

				<!--//item2014-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/article/10.1007%2Fs11432-013-4938-y">Learning a discriminative mid-level feature for action recognition.</a></div>
							<div class="name">	Cuiwei Liu, Mingtao Pei, Xinxiao Wu, Yu Kong, Yunde Jia.</div>
							<div class="position">SCIENCE CHINA Information Sciences, 2014.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6776501">Video Annotation via Image Groups from the Web.</a></div>
							<div class="name">Han Wang, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">IEEE TMM, 2014.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/chapter/10.1007%2F978-3-319-16814-2_32">Video Annotation by Incremental Learning from Grouped Heterogeneous Sources.</a></div>
							<div class="name">Han Wang, Hao Song, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">ACCV, 2014.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/chapter/10.1007%2F978-3-319-16814-2_42">Weakly Supervised Action Recognition and Localization Using Web Images.</a></div>
							<div class="name">Cuiwei Liu, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">ACCV, 2014.</div>
						</div><!--//source-->      
					</blockquote>
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6977062">Modeling the Relationship of Action, Object, and Scene.</a></div>
							<div class="name">Jing Liu, Xinxiao Wu, Yang Feng.</div>
							<div class="position">ICPR, 2014.</div>
						</div><!--//source-->      
					</blockquote>  
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6977384">Multi-group Adaptation for Event Recognition from Videos.</a></div>
							<div class="name">Yang Feng, Xinxiao Wu, Han Wang, Jing Liu.</div>
							<div class="position">ICPR, 2014.</div>
						</div><!--//source-->      
					</blockquote>               
				</div><!--//item-->

				<!--//item2013-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://www.sciencedirect.com/science/article/pii/S0925231213000180?via%3Dihub">Scene image retrieval via re-ranking semantic and packed dense interestpoints.</a></div>
							<div class="name">Han Wang, Wei Liang, Xinxiao Wu, Peng Teng.</div>
							<div class="position">Neurocomputing, 2013. </div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/document/6428638/">Action Recognition Using Multilevel Features and Latent Structural SVM.</a></div>
							<div class="name">Xinxiao Wu, Dong Xu, Lixin Duan, Jiebo Luo, Yunde Jia.</div>
							<div class="position">IEEE TCSVT, 2013.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6751185">Cross-View Action Recognition over Heterogeneous Feature Spaces.</a></div>
							<div class="name">Xinxiao Wu, Han Wang, Cuiwei Liu, Yunde Jia.</div>
							<div class="position">ICCV, 2013.</div>
						</div><!--//source-->      
					</blockquote>     
				</div><!--//item-->

				<!--//item2012-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://www.sciencedirect.com/science/article/pii/S0925231213000180?via%3Dihub">View-Invariant Action Recognition Using Latent Kernelized Structural SVM.</a></div>
							<div class="name">Xinxiao Wu, Yunde Jia.</div>
							<div class="position">ECCV, 2012. </div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6460747">Annotating videos from the web images.</a></div>
							<div class="name">Han Wang, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">ICPR, 2012.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6460886">Action recognition with discriminative mid-level features.</a></div>
							<div class="name">Cuiwei Liu, Yu Kong, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">ICPR, 2012.</div>
						</div><!--//source-->      
					</blockquote>  
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://link.springer.com/chapter/10.1007%2F978-3-642-34778-8_41">Transfer Discriminant-Analysis of Canonical Correlations for View-Transfer Action Recognition.</a></div>
							<div class="name">Xinxiao Wu, Cuiwei Liu, Yunde Jia.</div>
							<div class="position">PCM, 2012.</div>
						</div><!--//source-->      
					</blockquote>     
				</div><!--//item-->

				<!--//item2011 2010-->
				<div class="item">
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5995624">Action recognition using context and appearance distribution features.</a></div>
							<div class="name">Xinxiao Wu, Dong Xu, Lixin Duan, Jiebo Luo.</div>
							<div class="position">CVPR, 2011. </div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://www.sciencedirect.com/science/article/pii/S0262885609001723?via%3Dihub">Discriminative human action recognition in the learned hierarchical manifold space.</a></div>
							<div class="name">Lei Han, Xinxiao Wu, Wei Liang, Guangming Hou, Yunde Jia.</div>
							<div class="position">Image Vision Computing, 2010.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ac.els-cdn.com/S0031320310003511/1-s2.0-S0031320310003511-main.pdf?_tid=795890e9-7aa2-4d74-ae8d-d11db43dcb0c&acdnat=1530433391_8b83784ea9d72b7f52dee3c16774d2b7">Incremental discriminant-analysis of canonical correlations for action recognition.</a></div>
							<div class="name">Xinxiao Wu, Yunde Jia, Wei Liang.</div>
							<div class="position">Pattern Recognition, 2010.</div>
						</div><!--//source-->      
					</blockquote>  
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://www.sciencedirect.com/science/article/pii/S0167865508002973?via%3Dihub">Tracking articulated objects by learning intrinsic structure of motion.</a></div>
							<div class="name">Xinxiao Wu, Wei Liang, Yunde Jia.</div>
							<div class="position">Pattern Recognition Letters, 2009.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://www.sciencedirect.com/science/article/pii/S0167865509000713?via%3Dihub">Action recognition feedback-based framework for human pose reconstruction from monocular images.</a></div>
							<div class="name">Xinxiao Wu, Wei Liang, Yunde Jia.</div>
							<div class="position">Pattern Recognition Letters, 2009.</div>
						</div><!--//source-->      
					</blockquote> 
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5459448">Incremental discriminative-analysis of canonical correlations for action recognition.</a></div>
							<div class="name">Xinxiao Wu, Wei Liang, Yunde Jia.</div>
							<div class="position">ICCV, 2009.</div>
						</div><!--//source-->      
					</blockquote>   
					<blockquote class="quote">      
						<i class="fa fa-quote-left"></i>                            
						<div class="source">
						    <div class="papername"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4813416">Human action recognition using discriminative models in the learned hierarchical manifold space.</a></div>
							<div class="name">Lei Han, Wei Liang, Xinxiao Wu, Yunde Jia.</div>
							<div class="position">FG, 2008.</div>
						</div><!--//source-->      
					</blockquote>     
				</div><!--//item-->
				
			</div><!--//carousel-inner-->
		</div><!--//testimonials-carousel-->
		
	</section><!--//section-->
	
	<section id="Eudcation-section" class="education-section section">
		<h2 class="section-title">教学内容</h2>
		<div class="row">
			<div class="item col-md-6 col-sm-4">
				<div class="item-inner">
					<h3 class="degree">图像与视频处理</h3>
					<div class="education-body">
						硕士课程
					</div><!--//education-body-->
					<div class="time">秋季开学</div>
					<div class="desc">
						期末考试时间：<br>2019年1月8日（周二）13:20-14:50<br>地点：研究生楼606 
					</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-6 col-sm-4">
				<div class="item-inner">
					<h3 class="degree">计算感知</h3>
					<div class="education-body">
						博士课程
					</div><!--//education-body-->
					<div class="time">秋季开学</div>
					<div class="desc">
						暂无考试相关信息 
					</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			
		</div><!--//row-->
	</section><!--//section-->
	
	
	<section id="Project-section" class="skills-section section text-center">
		<h2 class="section-title">科研项目</h2>
		<div class="top-skills">
			<h3>MSVD-CN Dataset</h3>
			<div class="content">
				<p align="justify">MSVD-CN 数据集是MSVD数据集的拓展版本，在原来只有英文标注的MSVD数据集基础上提供了中文标注，主要用于video caption任务。数据集的1970个视频采集自YouTube，每个视频至少拥有5条不同的标注，总计有11,758条中文标注。标注工作由196名受过高等教育且普通话水平良好的志愿者完成，为了保证标注的规范性，我们为每个标注者提供了一段详细完整的规范说明，以确保标注的准确性及质量。由于汉语的复杂性及辞藻句式的丰富多样性，使得该数据集具备相当的挑战性。 </p>    
	        </div>     
	        <div class="image">
	        	<img class="dataset" src="assets/images/program/dataset1.jpg" style="width:100%;height:100%;" > 
	        </div>
            
		</div><!--//top-skills-->
		
		<div class="other-skills">
			<div class="misc-skills">
			 <a href="https://github.com/mcislab-machine-learning/MSVD-CN" class="mdl-button"><span class="skill-tag">去github看看</span></a>
			</div>
		</div><!--//other-skills-->
		
	</section><!--//skills-section-->
	
	
	
	
	
	
	
	
</div><!--//wrapper-->

<footer class="footer text-center">
	<div class="container">
		<p>媒体计算与智能系统实验室</p>
		<small class="copyright">北京市海淀区中关村南大街5号北京理工大学计算机学院　100081</small>
	</div><!--//container-->
</footer>

<!-- Javascript -->          
<script type="text/javascript" src="assets/plugins/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>  
<script type="text/javascript" src="assets/plugins/back-to-top.js"></script>
<script type="text/javascript" src="assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script> 
<script type="text/javascript" src="assets/plugins/easy-pie-chart/dist/jquery.easypiechart.min.js"></script>
<script type="text/javascript" src="assets/plugins/imagesloaded.pkgd.min.js"></script> 
<script type="text/javascript" src="assets/plugins/isotope.pkgd.min.js"></script>  
<script type="text/javascript" src="assets/plugins/viewer.min.js"></script>

<!-- custom js -->
<script type="text/javascript" src="assets/js/main.js"></script>

<!-- Style Switcher (REMOVE ON YOUR PRODUCTION SITE) -->
<script src="assets/js/demo/style-switcher.js"></script>     

</body>
</html>