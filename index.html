<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->  
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->  
<!--[if !IE]><!--> <html lang="en"> <!--<![endif]-->  
<head>
<title>吴心筱个人主页</title>
<!-- Meta -->
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="">    
<link rel="shortcut icon" href="">  
<link href='https://fonts.googleapis.com/css?family=Roboto:400,500,400italic,300italic,300,500italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
<!-- Global CSS -->
<link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
<!-- m CSS -->
<link rel="stylesheet" href="assets/plugins/font-awesome/css/font-awesome.css">
<link rel="stylesheet" href="assets/plugins/viewer.min.css">
<!-- Theme CSS -->  
<link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
<!-- wordcloud-js -->
<script src="https://d3js.org/d3.v5.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3-cloud/1.2.7/d3.layout.cloud.js"></script>

<style>
    .word-cloud {
      font-family: Arial, sans-serif;
      cursor: pointer;
      transition: font-size 0.2s ease-in-out;
    }
    .bold-word {
      font-weight: bold; /* 设置字体加粗 */
    }
  </style>

</head> 

<body>

<header class="header">
	<div class="top-bar container-fluid">
		<img id="viewer" class="background" alt="">
		<div class="actions">
			<a class="btn" href="indexEn.html">Translate to English</a>
		</div><!--//actions-->
	</div><!--//top-bar-->
	
	<div class="intro">
		<div class="container text-center">
			<img id="viewer" class="profile-image" src="assets/images/profile-image.jpg" alt="">
			<h1 class="name">吴心筱 博士</h1>
			<div class="title">教授 博士生导师</div>
			<div class="profile">
				<p align="justify">北京理工大学计算机学院教师。2010年7月在北京理工大学获得计算机应用技术工学博士学位，并获得北京理工大学优秀博士学位论文奖。2010年至2011年赴新加坡南洋理工大学计算机学院从事博士后研究。2011年12月加入北京理工大学计算机学院。2012年获得全国人工智能学会优秀博士学位论文奖。2013年入选校级优秀青年教师资助计划。在计算机视觉与人工智能顶级国际会议ICCV, CVPR, ECCV, AAAI, IJCAI, ACM MM以及SCI收录国际重要学术期刊IJCV, IEEE TIP, IEEE TMM, IEEE TNNLS, IEEE TCSVT, IEEE TCYB上发表多篇论文。负责国家自然科学青年基金、面上项目、教育部博士点基金、国防预研项目等多项科研项目以及多项校企合作项目。担任国际多媒体领域顶级期刊IEEE TMM编委。主要从事机器学习、视觉和语言、图像视频内容理解方向的研究。</p>
				<p align="justify" style="color: #FFFF55; font-weight: bold;font-size: 18px;">欢迎有志于视觉与语言、机器学习、人工智能研究的的同学们加入我们！ </p>
			</div><!--//profile-->
		</div><!--//container-->
	</div><!--//intro-->
	
	<div class="contact-info">
		<div class="container text-center">
			<ul class="list-inline">
				<li class="email"><i class="fa fa-envelope"></i>wuxinxiao@bit.edu.cn</li>
				<li class="website"><i class="fa fa-globe"></i>wuxinxiao.github.io</li>
			</ul>
		</div><!--//container-->
	</div><!--//contact-info-->
	
	<div class="page-nav-space-holder hidden-xs">
		<div id="page-nav-wrapper" class="page-nav-wrapper text-center">
			<div class="container">
				<ul id="page-nav" class="nav page-nav list-inline">
					<font size="+2">
						<li><a class="scrollto" href="#ResearchInterests-section">研究方向</a></li>
						<li><a class="scrollto" href="#SelectedPublications-section">代表性论文</a></li>
						<li><a class="scrollto" href="#Group-section">研究生小伙伴</a></li>
						<li><a class="scrollto" href="#Eudcation-section">教学内容</a></li>
					</font>
					
				</ul><!--//page-nav-->
			</div>
		</div><!--//page-nav-wrapper-->
	</div>
	
</header><!--//header-->

<!-- 模态框（Modal） -->
<div class="modal fade" id="citeModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog modal-dialog-centered" role="document">
		<div class="modal-content">
			<div class="modal-body">
				<pre id="citeText">
				</pre>
			</div>
		</div><!-- /.modal-content -->
	</div><!-- /.modal-dialog -->
</div><!-- /.modal -->

<div class="wrapper container">
	<section id="News-section" class="contact-section section">
		<h2 class="section-title">新闻</h2>
		<div class="news-intro">
			<div class="dialog">
				<ul class="list-unstyled service-list" id="news-lists">
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-12-10</p> 尚子睿和朱宇博论文“Video Summarization using Denoising Diffusion Probabilistic Model”被The 39th AAAI Conference on Artificial Intelligence (AAAI2025) 录用，祝贺子睿和宇博！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-08-13</p> 朱荣江和石语珩论文“大语言模型引导的开放域多标签动作识别”被《计算机研究与发展》录用，祝贺荣江和语珩！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-02-13</p> 杨硕论文“Dynamic Pathway for Query-Aware Feature Learning in Language-Driven Action Localization”被IEEE Transactions on Multimedia (TMM) 录用，祝贺杨硕！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2024-01-23</p> 石语珩和林瀚熙论文“Commonsense Knowledge Prompting for Few-shot Action Recognition in Videos”被IEEE Transactions on Multimedia (TMM) 录用，祝贺语珩和瀚熙！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-12-09</p> 杨硕和王泳棋论文“Multi-modal Prompting for Open-vocabulary Video Visual Relationship Detection”被The 38th AAAI Conference on Artificial Intelligence (AAAI2024) 录用，祝贺杨硕和泳棋！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-12-09</p> 齐雅昀论文“Relational Distant Supervision for Image Captioning without Image-text Pairs”被The 38th AAAI Conference on Artificial Intelligence (AAAI2024) 录用，祝贺雅昀！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-07-26</p> 杨硕和尚子睿论文“Probability Distribution Based Frame-supervised Language-driven Action Localization”被The 31st ACM International Conference on Multimedia (ACM MM2023) 录用，祝贺杨硕和子睿！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-07-17</p> 赵文天论文“Boosting Entity-aware Image Captioning with Multi-modal Knowledge Graph”被IEEE Transactions on Multimedia (TMM) 录用，祝贺文天！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-04-20</p> 邵世通和陈焕然论文“Teaching What You Should Teach: A Data-Based Distillation Method”被International Joint Conference on Artificial Intelligence (IJCAI2023) 录用，祝贺世通和焕然！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-03-29</p> 朱宇博论文“Topic-aware Video Summarization using Multimodal Transformer”被Pattern Recognition (PR) 录用，祝贺宇博！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-03-17</p> 纪校锋论文“Counterfactual Inference for Visual Relationship Detection in Videos”被IEEE International Conference on Multimedia and Expo (ICME2023) 录用，祝贺校锋！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-02-28</p> 陈谨论文“Meta-causal Learning for Single Domain Generalization”被The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR2023) 录用，祝贺陈谨！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-01-19</p> 赵文天和齐雅昀获得首届“兴智杯”全国人工智能创新应用大赛多模态技术创新赛二等奖！祝贺文天和雅昀！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2023-01-06</p> 李彤论文“Sentimental Visual Captioning using Multimodal Transformer”被International Journal of Computer Vision (IJCV) 录用，祝贺李彤！</li>					
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-12-05</p> 田孟潇论文“Adaptive Latent Graph Representation Learning for Image-Text Matching”被IEEE Transactions on Image Processing (TIP) 录用，祝贺孟潇！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-05-29</p> 赵文天论文“Learning Cooperative Neural Modules for Stylized Image Captioning”被International Journal of Computer Vision (IJCV) 录用，祝贺文天！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-04-21</p> 杨硕论文“Entity-Aware and Motion-Aware Transformers for Language-driven Action Localization”被International Joint Conference on Artificial Intelligence (IJCAI2022) 录用，祝贺杨硕！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2022-03-07</p> 林瀚熙论文“Adaptive Recursive Circle Framework for Fing-grained Action Recognition”被IEEE International Conference on Multimedia and Expo (ICME2022) 录用，祝贺瀚熙！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-12-01</p> 陈谨和纪校锋论文“Adaptive Image-to-video Scene Graph Generation via Knowledge Reasoning and Adversarial Learning”被36th AAAI Conference on Artificial Intelligence (AAAI2022) 录用，祝贺陈谨和校锋！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-09-29</p> 赵文天论文“Multi-modal Dependency Tree for Video Captioning”被Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS2021) 录用，祝贺文天！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-03-13</p> 陈谨论文“Sequential Instance Refinement for Cross-domain Object Detection in Images”被IEEE Transactions on Image Processing (TIP) 录用，祝贺陈谨！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-03-12</p> 侯静怡和齐雅昀论文“跨语言知识蒸馏的视频中文字幕生成”被《计算机学报》录用，祝贺静怡和雅昀！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2021-03-07</p> 李彤论文“Image Captioning with Inherent Sentiment”被IEEE International Conference on Multimedia and Expo (ICME2021 Oral) 录用，祝贺李彤！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-12-02</p> 赵建伟和王瑞琦论文“Anticipating Future Relations via Graph Growing for Action Prediction”被The 35th AAAI Conference on Artificial Intelligence (AAAI2021) 录用，祝贺建伟和瑞琦！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-12-02</p> 陈谨论文“Spatial-temporal Causal Inference for Partial Image-to-video Adaptation”被35th AAAI Conference on Artificial Intelligence (AAAI2021) 录用，祝贺陈谨！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-11-24</p> 赵文天论文“Cross-domain Image Captioning via Cross-modal Retrieval and Model Adaptation”被IEEE Transactions on Image Processing (TIP) 录用，祝贺文天！</li>
				 	<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-11-20</p> 王瑞琦论文“Spatial-Temporal Relation Reasoning for Action Prediction in Videos”被International Journal of Computer Vision (IJCV) 录用，祝贺瑞琦！</li>
				    <li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-09-25</p> 陈谨论文“Domain Adversarial Reinforcement Learning for Partial Domain Adaptation”被IEEE Transactions on Neural Networks and Learning Systems (TNNLS) 录用，祝贺陈谨！</li>
					<li class="news-item"><i class="fa fa-bell-o" aria-hidden="true" ></i> <p>2020-07-26</p> 陈佳露论文“Preserving Global and Local Temporal Consistency for Arbitrary Video Style Transfer”被ACM Multimedia 2020录用，祝贺佳露！</li>
				</ul>
			</div><!--//diaplog-->
			<div style="text-align: center; margin-top: 2rem;">
				<a href="javascript:void(0)" id="load-more" onclick="loadMoreNews()">---- 更多新闻 ----</a>
			</div>
			<!-- <p id="load-more" class="text-center" style="cursor: pointer; color: #00BCD4;">————— 点击查看更多 ——————</p> -->
		</div><!--//news-intro-->
	</section><!--//section-->

	<section id="ResearchInterests-section" class="contact-section section">
		<h2 class="section-title">研究方向</h2>
		<!-- <div id="word-cloud" class="dialog" style="text-align:center"></div> -->
		<div class="dialog" style="text-align:center">
			<td style="width: 199px; font-family: Helvetica,Arial,sans-serif;">
			<font size="+1" color="#00A7BE">
				<big><span style="font-weight: bold;">人工智能</span></big>&nbsp;&nbsp;
				视频定位&nbsp;
				<big style="font-weight: bold;">计算机视觉</big>&nbsp;&nbsp;<br>
				<span>视觉描述生成</span>&nbsp;&nbsp;
				<big><span style="font-weight: bold;">视觉和语言</span></big>&nbsp;
				<small>视频风格迁移</small>&nbsp;&nbsp;<br>
				<small>动物交互分析</small>&nbsp;人体动作识别&nbsp;&nbsp;
				<small><big><span style="font-weight: bold;">迁移学习&nbsp;</span></big></small><br>
				<span style="font-weight: bold;">领域自适应</span>&nbsp;&nbsp; 
				<small> 跨域目标检测 </small>
				<span style="font-weight: bold;">领域泛化</span>&nbsp;<br>
				<small>视频摘要生成</small>&nbsp;
				<span style="font-weight: bold;">多模态视频分析理解</span>&nbsp;&nbsp;				
				<small>视觉故事生成</small> <br>&nbsp;
			</font>
          </td>
		</div>
	</section><!--//section-->

	<section id="SelectedPublications-section" class="portfolio-section section">
		<h2 class="section-title">代表性论文</h2>
		<h3 style="text-align: center;font-size: 22px; color: #00BCD4; margin-top: 1.0rem; margin-bottom: 2.0rem;">期刊文章</h3>
		<div class="items-wrapper-journal isotope row" id="items-wrapper" style="height: auto;">
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer43" class="img-responsive" src="assets/images/portfolio/portfolio-43.jpg" data-original="assets/images/papers/paper43.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Dynamic Pathway for Query-Aware Feature Learning in Language-Driven Action Localization.</a></h3>
						<div class="meta">Shuo Yang, Xinxiao Wu, Zirui Shang, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/TMM_Dynamic_Pathway_for_Query-Aware_Feature_Learning_in_Language-Driven_Action_Localization.pdf">[PDF]</a>
							<!-- <a href="https://github.com/OldStone0124/Knowledge-Prompting-for-FSAR">[CODE]</a> -->
							<a data-toggle="modal" data-target="#citeModal" data-whatever="43">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer41" class="img-responsive" src="assets/images/portfolio/portfolio-41.jpg" data-original="assets/images/papers/paper41.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Commonsense Knowledge Prompting for Few-shot Action Recognition in Videos.</a></h3>
						<div class="meta">Yuheng Shi, Xinxiao Wu, Hanxi Lin.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/TMM_Few-shot_Action_Recognition.pdf">[PDF]</a>
							<a href="https://github.com/OldStone0124/Knowledge-Prompting-for-FSAR">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="41">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer37" class="img-responsive" src="assets/images/portfolio/portfolio-37.jpg" data-original="assets/images/papers/paper37.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Boosting Entity-aware Image Captioning with Multi-modal Knowledge Graph.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/Boosting Entity-aware.pdf">[PDF]</a>
							<a href="https://github.com/wentian-zhao/entity-aware-caption/tree/main">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="37">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer36" class="img-responsive" src="assets/images/portfolio/portfolio-36.jpg" data-original="assets/images/papers/paper36.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Topic-aware Video Summarization using Multimodal Transformer.</a></h3>
						<div class="meta">Yubo Zhu, Wentian Zhao, Rui Hua, Xinxiao Wu.</div>
						<div class="action">Pattern Recognition (PR), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/Topic-aware video.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="36">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer39" class="img-responsive" src="assets/images/portfolio/portfolio-39.jpg" data-original="assets/images/papers/paper39.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Sentimental Visual Captioning using Multimodal Transformer.</a></h3>
						<div class="meta">Xinxiao Wu, Tong Li</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/IJCV2023-caption multimodal.pdf">[PDF]</a>
							<a href="https://github.com/ezeli/InSentiCap_ext">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="39">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer34" class="img-responsive" src="assets/images/portfolio/portfolio-34.jpg" data-original="assets/images/papers/paper34.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Adaptive Latent Graph Representation Learning for Image-Text Matching.</a></h3>
						<div class="meta">Mengxiao Tian, Xinxiao Wu, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2022</div>
						<div class="link">
							<a href="assets/papers/2022/ALGRL.pdf">[PDF]</a>
							<a href="https://github.com/Mengxiao-Tian/ALGR">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="34">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer33" class="img-responsive" src="assets/images/portfolio/portfolio-33.jpg" data-original="assets/images/papers/paper33.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Learning Cooperative Neural Modules for Stylized Image Captioning.</a></h3>
						<div class="meta">Xinxiao Wu, Wentian Zhao, Jiebo Luo</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/LCNM.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="33">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer28" class="img-responsive" src="assets/images/portfolio/portfolio-28.jpg" data-original="assets/images/papers/paper28.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Spatial–Temporal Relation Reasoning for Action Prediction in Videos.</a></h3>
						<div class="meta">Xinxiao Wu, Ruiqi Wang, Jingyi Hou, Hanxi Lin, Jiebo Luo.</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Spatial–Temporal Relation Reasoning.pdf">[PDF]</a>
							<a href="https://github.com/0HaNC/Graph-Action-Prediction">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="28">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer27" class="img-responsive" src="assets/images/portfolio/portfolio-27.jpg" data-original="assets/images/papers/paper27.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Sequential Instance Refinement for Cross-Domain Object Detection in Images.</a></h3>
						<div class="meta">Jin Chen, Xinxiao Wu, Lixin Duan, Lin Chen.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/SIR.pdf">[PDF]</a>
							<a href="https://github.com/ChenJinBIT/SIR">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="27">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer25" class="img-responsive" src="assets/images/portfolio/portfolio-25.jpg" data-original="assets/images/papers/paper25.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Captioning_via_Retrieval.pdf">[PDF]</a>
							<a href="https://github.com/enp7s0/cross-domain">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="25">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer22" class="img-responsive" src="assets/images/portfolio/portfolio-22.jpg" data-original="assets/images/papers/paper22.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Exploiting Informative Video Segments for Temporal Action Localization.</a></h3>
						<div class="meta">Che Sun, Hao Song, Xinxiao Wu, Yunde Jia, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/STAN.pdf">[PDF]</a>
							<a href="https://github.com/2120171054/Exploiting-Informative-Video-Segments-for-Temporal-Action-Localization">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="22">[BibTeX]</a>
						</div>						
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer21" class="img-responsive" src="assets/images/portfolio/portfolio-21.jpg" data-original="assets/images/papers/paper21.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Domain Adversarial Reinforcement Learning for Partial Domain Adaptation.</a></h3>
						<div class="meta">Jin Chen, Xinxiao Wu, Lixin Duan, Shenghua Gao.</div>
						<div class="action">IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/DARL.pdf">[PDF]</a>
							<a href="https://github.com/ChenJinBIT/DARL">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="21">[BibTeX]</a>
						</div>						
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer13" class="img-responsive" src="assets/images/portfolio/portfolio-13.jpg" data-original="assets/images/papers/paper13.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Confidence-guided self refinement for action prediction in untrimmed videos.</a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Ruiqi Wang, Jiebo Luo, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/SPR-Net.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="13">[BibTeX]</a>
						</div>							
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer14" class="img-responsive" src="assets/images/portfolio/portfolio-14.jpg" data-original="assets/images/papers/paper14.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Joint Learning of Multiple Latent Domains and Deep Representations for Domain Adaptation.</a></h3>
						<div class="meta">Xinxiao Wu, Jin Chen, Feiwu Yu, Mingyu Yao, Jiebo Luo.</div>
						<div class="action">IEEE Transactions on Cybernetics (T-CYB), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/Multiple_Latent_Domains_and_Deep_Representation.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="14">[BibTeX]</a>
						</div>						
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer15" class="img-responsive" src="assets/images/portfolio/portfolio-15.jpg" data-original="assets/images/papers/paper15.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Learning Normal Patterns via Adversarial Attention-Based Autoencoder for Abnormal Event Detection in Videos.</a></h3>
						<div class="meta">Hao Song, Che Sun, Xinxiao Wu, Mei Chen, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/Ada-Net.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="15">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer12" class="img-responsive" src="assets/images/portfolio/portfolio-12.jpg" data-original="assets/images/papers/paper12.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Exploiting Images for Video Recognition: Heterogeneous Feature Augmentation via Symmetric Adversarial Learning.</a></h3>
						<div class="meta">Feiwu Yu, Xinxiao Wu, Jialu Chen, Lixin Duan.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP),2019</div>
						<div class="link">
							<a href="assets/papers/2019/Sym-GAN.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="12">[BibTeX]</a>
						</div>  
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer11" class="img-responsive" src="assets/images/portfolio/portfolio-11.jpg" data-original="assets/images/papers/paper11.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Temporal Action Localization in Untrimmed Videos using Action Pattern Trees.</a></h3>
						<div class="meta">Hao Song, Xinxiao Wu, Bing Zhu, Yuwei Wu, Mei Chen, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2019</div>
						<div class="link">
							<a href="assets/papers/2019/Action_Pattern_Trees.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="11">[BibTeX]</a>
						</div> 
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer4" class="img-responsive" src="assets/images/portfolio/portfolio-4.jpg" data-original="assets/images/papers/paper4.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Extracting Key Segments of Videos for Event Detection by Learning From Web Sources.</a></h3>
						<div class="meta">Hao Song, Xinxiao Wu, Wennan Yu, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2018</div>
						<div class="link">
							<a href="assets/papers/2018/Extracting_Key_Segments.pdf">[PDF]</a>
							<a href="https://github.com/mcislab840832/Extracting-Key-Segments-of-Videos-for-Event-Detection">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="4">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer3" class="img-responsive" src="assets/images/portfolio/portfolio-3.jpg" data-original="assets/images/papers/paper3.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Content-Attention Representation by Factorized Action-Scene Network for Action Recognition. </a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Yuchao Sun, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2017</div>
						<div class="link">
							<a href="assets/papers/2018/FASNet.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="3">[BibTeX]</a>
						</div>
					</div><!--//content-->                  
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer5" class="img-responsive" src="assets/images/portfolio/portfolio-5.jpg" data-original="assets/images/papers/paper5.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>A Hierarchical Video Description for Complex Activity Understanding.</a></h3>
						<div class="meta">Cuiwei Liu, Xinxiao Wu, Yunde Jia.</div>
						<div class="action">International Journal of Computer Vision (IJCV), 2016</div>
						<div class="link">
							<a href="assets/papers/2016/Hierarchical_Video_Description.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="5">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer10" class="img-responsive" src="assets/images/portfolio/portfolio-10.jpg" data-original="assets/images/papers/paper10.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Cross-View Action Recognition Over Heterogeneous Feature Spaces.</a></h3>
						<div class="meta">Xinxiao Wu, Han Wang, Cuiwei Liu, Yunde Jia.</div>
						<div class="action">IEEE Transactions on Image Processing (TIP), 2015</div>
						<div class="link">
							<a href="assets/papers/2015/HTDCC.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="10">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer9" class="img-responsive" src="assets/images/portfolio/portfolio-9.jpg" data-original="assets/images/papers/paper9.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Video Annotation via Image Groups from the Web. </a></h3>
						<div class="meta">Han Wang, Xinxiao Wu, and Yunde Jia.</div>
						<div class="action">IEEE Transactions on Multimedia (TMM), 2014</div>
						<div class="link">
							<a href="assets/papers/2014/GDA.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="9">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->		
		</div><!-- item-wrapper-journal-->
		<div style="text-align: center;">
			<a href="javascript:void(0)" id="load-more-items" onclick="loadMoreJournalItems()">---- 更多期刊文章 ----</a>
		</div><!--//item-wrapper-->
		<h3 style="text-align: center;font-size: 22px; color: #00BCD4; margin-top: 3.0rem; margin-bottom: 2.0rem;">会议论文</h3>
		<div class="items-wrapper-paper isotope row" id="items-wrapper" style="height: auto;">
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer42" class="img-responsive" src="assets/images/portfolio/portfolio-42.jpg" data-original="assets/images/papers/paper42.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Relational Distant Supervision for Image Captioning without Image-text Pairs.</a></h3>
						<div class="meta">Yayun Qi, Wentian zhao, Xinxiao Wu.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/AAAI_2024_Relational_Distant_Supervision_for_Image_Captioning_without_Image-text_Pairs.pdf">[PDF]</a>
							<a href="https://github.com/MNOPQYY/Relational-distant-supervision-image-captioning">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="42">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer40" class="img-responsive" src="assets/images/portfolio/portfolio-40.jpg" data-original="assets/images/papers/paper40.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Multi-Modal Prompting for Open-Vocabulary Video Visual Relationship Detection.</a></h3>
						<div class="meta">Shuo Yang, Yongqi Wang, Xinxiao Wu.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2024</div>
						<div class="link">
							<a href="assets/papers/2024/AAAI_2024_open_vocabulary_video_relationship_detection.pdf">[PDF]</a>
							<a href="https://github.com/wangyongqi558/MMP_OV_VidVRD">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="40">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer38" class="img-responsive" src="assets/images/portfolio/portfolio-38.jpg" data-original="assets/images/papers/paper38.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Probability Distribution Based Frame-supervised Language-driven Action Localization.</a></h3>
						<div class="meta">Shuo Yang, Zirui Shang, Xinxiao Wu.</div>
						<div class="action">The 31st ACM International Conference on Multimedia (ACM MM), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/MM2023-3653.pdf">[PDF]</a>
							<a href="https://github.com/shuoyang129/Distrbution-based-Frame-Supervised-LDAL">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="38">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer35" class="img-responsive" src="assets/images/portfolio/portfolio-35.jpg" data-original="assets/images/papers/paper35.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Meta-causal Learning for Single Domain Generalization.</a></h3>
						<div class="meta">Jin Chen, Zhi Gao, Xinxiao Wu, Jiebo Luo.</div>
						<div class="action">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023</div>
						<div class="link">
							<a href="assets/papers/2023/Meta-causal.pdf">[PDF]</a>
							<a href="https://github.com/zhigao2017/Meta-causal">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="35">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer32" class="img-responsive" src="assets/images/portfolio/portfolio-32.jpg" data-original="assets/images/papers/paper32.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Entity-aware and Motion-aware Transformers for Language-driven Action Localization in Videos.</a></h3>
						<div class="meta">Shuo Yang, Xinxiao Wu.</div>
						<div class="action">International Joint Conference on Artificial Intelligence (IJCAI), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/EAMAT.pdf">[PDF]</a>
							<a href="https://github.com/shuoyang129/EAMAT">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="32">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer31" class="img-responsive" src="assets/images/portfolio/portfolio-31.jpg" data-original="assets/images/papers/paper31.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Adaptive Recursive Circle Framework for Fing-grained Action Recognition.</a></h3>
						<div class="meta">Hanxi Lin, Wentian Zhao, Xinxiao Wu.</div>
						<div class="action">IEEE International Conference on Multimedia and Expo (ICME), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/ARC.pdf">[PDF]</a>
							<a href="https://github.com/0HaNC/ARC-ActionRecog/">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="31">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer30" class="img-responsive" src="assets/images/portfolio/portfolio-30.jpg" data-original="assets/images/papers/paper30.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Adaptive Image-to-video Scene Graph Generation via Knowledge Reasoning and Adversarial Learning.</a></h3>
						<div class="meta">Jin Chen, Xiaofeng Ji, Xinxiao Wu.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2022</div>	
						<div class="link">
							<a href="assets/papers/2022/I2VSGG.pdf">[PDF]</a>
							<a href="https://github.com/Ego-J/I2VSGG">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="30">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer29" class="img-responsive" src="assets/images/portfolio/portfolio-29.jpg" data-original="assets/images/papers/paper29.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Multi-modal Dependency Tree for Video Captioning.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu, Jiebo Luo.</div>
						<div class="action">Neural Information Processing Systems (NeurIPS), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Multi-modal Dependency Tree.pdf">[PDF]</a>
							<a href="https://github.com/wentian-zhao/tree_video_caption">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="29">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer26" class="img-responsive" src="assets/images/portfolio/portfolio-26.jpg" data-original="assets/images/papers/paper26.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Image Captioning with Inherent Sentiment.</a></h3>
						<div class="meta">Tong Li, Yunhui Hu, Xinxiao Wu.</div>
						<div class="action">IEEE International Conference on Multimedia and Expo (ICME) oral, 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/InSenti-Cap.pdf">[PDF]</a>
							<a href="https://github.com/ezeli/InSentiCap_model">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="26">[BibTeX]</a>
						</div>
					</div><!--//content-->     					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer24" class="img-responsive" src="assets/images/portfolio/portfolio-24.jpg" data-original="assets/images/papers/paper24.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Spatial-temporal Causal Inference for Partial Image-to-video Adaptation.</a></h3>
						<div class="meta">Jin Chen, Xinxiao Wu, Yao Hu, Jiebo Luo.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/Spatial-temporal_Causal_Inference.pdf">[PDF]</a>
							<a href="https://github.com/ChenJinBIT/HPDA">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="24">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer23" class="img-responsive" src="assets/images/portfolio/portfolio-23.jpg" data-original="assets/images/papers/paper23.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Anticipating Future Relations via Graph Growing for Action Prediction.</a></h3>
						<div class="meta">Xinxiao Wu, Jianwei Zhao, Ruiqi Wang.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2021</div>	
						<div class="link">
							<a href="assets/papers/2021/LST-GCN.pdf">[PDF]</a>
							<a href="https://github.com/wuxinxiao/LST-GCN">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="23">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer16" class="img-responsive" src="assets/images/portfolio/portfolio-16.jpg" data-original="assets/images/papers/paper16.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Preserving Global and Local Temporal Consistency for Arbitrary Video Style Transfer.</a></h3>
						<div class="meta">Xinxiao Wu, Jialu Chen.</div>
						<div class="action">ACM International Conference on Multimedia (ACM MM), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/Preserving_Temporal_Consistency.pdf">[PDF]</a>
							<a href="https://github.com/mcislab-machine-learning/videostyletransfer">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="16">[BibTeX]</a>
						</div>	
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer6" class="img-responsive" src="assets/images/portfolio/portfolio-6.jpg" data-original="assets/images/papers/paper6.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Joint Commonsense and Relation Reasoning for Image and Video Captioning.</a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Xiaoxun Zhang, Yayun Qi, Yunde Jia, Jiebo Luo.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/C-R_reasoning.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="6">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->		
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer7" class="img-responsive" src="assets/images/portfolio/portfolio-7.jpg" data-original="assets/images/papers/paper7.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>MemCap: Memorizing Style Knowledge for Image Captioning.</a></h3>
						<div class="meta">Wentian Zhao, Xinxiao Wu, Xiaoxun Zhang.</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2020</div>
						<div class="link">
							<a href="assets/papers/2020/MemCap.pdf">[PDF]</a>
							<a href="https://github.com/entalent/MemCap">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="7">[BibTeX]</a>
						</div>	
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer8" class="img-responsive" src="assets/images/portfolio/portfolio-8.jpg" data-original="assets/images/papers/paper8.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning.</h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Wentian Zhao, Jiebo Luo, Yunde Jia.</div>
						<div class="action">International Conference on Computer Vision (ICCV),2019</div>
						<div class="link">
							<a href="assets/papers/2019/Joint_Syntax_Representation_Learning_and_Visual_Cue_Translation.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="8">[BibTeX]</a>
						</div>
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer1" class="img-responsive" src="assets/images/portfolio/portfolio-1.jpg" data-original="assets/images/papers/paper1.jpg" alt=""/>
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition.</a></h3>
						<div class="meta">Jingyi Hou, Xinxiao Wu, Jin Chen, Jiebo Luo, Yunde Jia</div>
						<div class="action">AAAI Conference on Artificial Intelligence (AAAI), 2018</div> 
						<div class="link">
							<a href="assets/papers/2018/Unsupervised_Mid-Level_Video_Representation.pdf">[PDF]</a>
							<a href="https://github.com/mcislab840832/Mid-Level-video-representation-for-action-recognition">[CODE]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="1">[BibTeX]</a>
						</div>
					</div><!--//content-->    					            
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer2" class="img-responsive" src="assets/images/portfolio/portfolio-2.jpg" data-original="assets/images/papers/paper2.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks.</a></h3>
						<div class="meta">Feiwu Yu, Xinxiao Wu, Yuchao Sun, Lixin Duan.</div>
						<div class="action">International Joint Conference on Artificial Intelligence (IJCAI), 2018</div>
						<div class="link">
							<a href="assets/papers/2018/HiGAN.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="2">[BibTeX]</a>
						</div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer17" class="img-responsive" src="assets/images/portfolio/portfolio-17.jpg" data-original="assets/images/papers/paper17.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Cross-View Action Recognition over Heterogeneous Feature Spaces.</a></h3>
						<div class="meta">Xinxiao Wu, Han Wang, Cuiwei Liu, Yunde Jia.</div>
						<div class="action">IEEE International Conference on Computer Vision (ICCV), 2013</div>
						<div class="link">
							<a href="assets/papers/2013/HTDCC.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="17">[BibTeX]</a>
						</div>
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer18" class="img-responsive" src="assets/images/portfolio/portfolio-18.jpg" data-original="assets/images/papers/paper18.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>View-Invariant Action Recognition Using Latent Kernelized Structural SVM.</a></h3>
						<div class="meta">Xinxiao Wu, Yunde Jia.</div>
						<div class="action">European Conference on Computer Vision (ECCV), 2012</div>
						<div class="link">
							<a href="assets/papers/2012/Latent_Kernelized_Structural_SVM.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="18">[BibTeX]</a>
						</div>	
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/portfolio/portfolio-19.jpg" data-original="assets/images/papers/paper19.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Action recognition using context and appearance distribution features.</a></h3>
						<div class="meta">Xinxiao Wu, Dong Xu, Lixin Duan, Jiebo Luo.</div>
						<div class="action">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011</div>
						<div class="link">
							<a href="assets/papers/2011/AFMKL.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="19">[BibTeX]</a>
						</div>	
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-12 col-xs-12 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/portfolio/portfolio-20.jpg" data-original="assets/images/papers/paper20.jpg" alt="" />
					</figure>
					<div class="content text-left">
						<h3 class="sub-title"><a>Incremental discriminative-analysis of canonical correlations for action recognition.</a></h3>
						<div class="meta">Xinxiao Wu, Wei Liang, Yunde Jia.</div>
						<div class="action">IEEE International Conference on Computer Vision (ICCV), 2009</div>	
						<div class="link">
							<a href="assets/papers/2011/IDCC.pdf">[PDF]</a>
							<a data-toggle="modal" data-target="#citeModal" data-whatever="20">[BibTeX]</a>
						</div>	
					</div><!--//content-->    				              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//item-wrapper-->
		
		<div style="text-align: center;">
			<a href="javascript:void(0)" id="load-more-items" onclick="loadMorePaperItems()">---- 更多会议论文 ----</a>
		</div>
		
	</section><!--//section-->		
	
	<section id="Group-section" class="group-section section">
		<h2 class="section-title">研究生小伙伴</h2>
		<div class="items-wrapper isotope row">
			<div class="item frontend col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer12" class="img-responsive" src="assets/images/group/tianmengxiao.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">田孟潇</a></h3>
						<div class="meta">博士生</div>
						<div class="action">video understanding</a></div>
					</div><!--//content-->                  
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer18" class="img-responsive" src="assets/images/group/qiyayun.jpg" alt="" style="border-radius: 70%" />
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">齐雅昀</a></h3>
						<div class="meta">博士生</div>
						<div class="action">video caption</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer18" class="img-responsive" src="assets/images/group/chenjun.jpg" alt="" style="border-radius: 70%" />
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">陈军</a></h3>
						<div class="meta">博士生</div>
						<div class="action">incremental learning</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/group/shangzirui.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">尚子睿</a></h3>
						<div class="meta">博士生</div>
						<div class="action">video grounding</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!-- // row1 -->
		<div class="row">
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/group/songyiqi.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">宋奕圻</a></h3>
						<div class="meta">博士生</div>
						<div class="action">multimodal reasoning</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->			
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/group/lihongxi.jpeg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">李鸿熙</a></h3>
						<div class="meta">硕士生</div>
						<div class="action">video summarization</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer19" class="img-responsive" src="assets/images/group/huangxiqing.jpeg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">黄希晴</a></h3>
						<div class="meta">硕士生</div>
						<div class="action">action segmentation</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/group/wangyongqi.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">王泳棋</a></h3>
						<div class="meta">硕士生</div>
						<div class="action">video relation detection</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!-- // row2 -->
		<div class="row">
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer20" class="img-responsive" src="assets/images/group/wangziyi.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">王子奕</a></h3>
						<div class="meta">硕士生</div>
						<div class="action">domain generalization</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer21" class="img-responsive" src="assets/images/group/zhurongjiang.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">朱荣江</a></h3>
						<div class="meta">硕士生</div>
						<div class="action">video action recognition</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-xs-6 ">
				<div class="item-inner">
					<figure class="figure">
						<img id="viewer21" class="img-responsive" src="assets/images/group/tanyunteng.jpg" alt="" style="border-radius: 70%"/>
					</figure>
					<div class="content text-center">
						<h3 class="sub-title">谭云腾</a></h3>
						<div class="meta">硕士生</div>
						<div class="action">LLM-based agents</a></div>
					</div><!--//content-->    					              
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!-- // row3-->>
	</section><!--//section-->
	<section id="Group-section" class="education-section section">
		<h2 class="section-title-2">毕业生</h2>	
		<h3  style="text-align: center;font-size: 20px; color: #00BCD4; margin-top: 1.7rem;">—— 博士毕业生 ——</h3>
		<div class="row">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">杨硕</h3>
					<div class="education-body">深圳北理莫斯科大学 副教授</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">陈谨</h3>
					<div class="education-body">航天智能院 研发工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">赵文天</h3>
					<div class="education-body">北京理工大学 博士后</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row-->
		<div class="row">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">王晗</h3>
					<div class="education-body">北京林业大学 副教授</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">宋浩</h3>
					<div class="education-body">腾讯 研究员</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">侯静怡</h3>
					<div class="education-body">北京科技大学 师资博士后</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row-->
		<h3  style="text-align: center; font-size: 20px; color: #00BCD4;">—— 硕士毕业生 ——</h3>
		
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">朱宇博</h3>
					<div class="education-body">中国科学院空天信息创新研究院 助理工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">石语珩</h3>
					<div class="education-body">中国银行总行 信科管培生</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">闻子涵</h3>
					<div class="education-body">中国空间技术研究院 算法工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
		</div><!--//row-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">纪校锋</h3>
					<div class="education-body">字节跳动 算法工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">伊嘉诚</h3>
					<div class="education-body">中国人民解放军战略支援部队 助理工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">李彤</h3>
					<div class="education-body">阿里巴巴 算法工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">林瀚熙</h3>
					<div class="education-body">字节跳动 算法工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">刘超</h3>
					<div class="education-body">阿里巴巴 高级算法工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">余非梧</h3>
					<div class="education-body">阿里达摩院 开发工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">朱冰</h3>
					<div class="education-body">阿里云 数据工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">孙宇超</h3>
					<div class="education-body">旷视科技 算法研究员</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">王瑞琦</h3>
					<div class="education-body">小米 产品经理</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row-->
		<div class="row ms-item">
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">滑蕊</h3>
					<div class="education-body">航空工业制造院 信息化管理</div>
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">陈佳露</h3>
					<div class="education-body">小米 算法工程师</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-4 col-sm-4">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">李天宇</h3>
					<div class="education-body">京投 管培生</div>
				</div><!--//item-inner-->
			</div><!--//item-->
		</div><!--//row-->
		
		<div style="text-align: center;">
			<a href="javascript:void(0)" id="load-more-group" onclick="loadMoreGroup()">---- 更多毕业生 ----</a>
		</div>
	</section><!--//section-->

	<section id="Eudcation-section" class="education-section section">
		<h2 class="section-title-2">教学内容</h2>
		<div class="row">
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">编译原理与设计</h3>
					<div class="education-body">
						本科生课程
					</div><!--//education-body-->
					<div class="time">春季开学</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">人工智能基础</h3>
					<div class="education-body">
						本科生课程
					</div><!--//education-body-->
					<div class="time">秋季开学</div>
				</div><!--//item-inner-->
			</div><!--//item-->	
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">图像与视频处理</h3>
					<div class="education-body">
						硕士课程
					</div><!--//education-body-->
					<div class="time">秋季开学</div>
					<!-- <div class="ppt"><a href="assets/cources/Image and Video Processing/3.3 Morphological Filtering for Image Enhancement and Detection.pptx">3.3 Morphological Filtering for Image Enhancement and Detection</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.4 Wavelet Denoising for Image Enhancement.pptx">3.4 Wavelet Denoising for Image Enhancement</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.5 Basic Methods for Image Restoration and Identification.pptx">3.5 Basic Methods for Image Restoration and Identification</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.10 Motion Detection and Estimation.pptx">3.10 Motion Detection and Estimation</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/3.11 Video Enhancement and Restoration.pptx">3.11 Video Enhancement and Restoration</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/Handbook of Image and Video Processing_Reference.pdf">Handbook of Image and Video Processing_Reference</a></div>
					<div class="ppt"><a href="assets/cources/Image and Video Processing/Image Compression.pptx">Image Compression</a></div> -->
				</div><!--//item-inner-->
			</div><!--//item-->
			<div class="item col-md-3 col-sm-3">
				<div class="item-inner" style="text-align: center;">
					<h3 class="degree">计算感知</h3>
					<div class="education-body">
						博士课程
					</div><!--//education-body-->
					<div class="time">秋季开学</div>
					<!-- <div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture1-Human Activity Analysis.rar">Lecture1-Human Activity Analysis</a></div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture2-object recognition.rar">Lecture2-object recognition</a></div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture3-Transfer Learning.rar">Lecture3-Transfer Learning</a></div>
					<div class="ppt"><a href="assets/cources/Computational Perception 2020/Lecture4-Vision and Language.pptx">Lecture4-Vision and Language</a></div> -->
				</div><!--//item-inner-->
			</div><!--//item-->			
		</div><!--//row-->
	</section><!--//section-->
		
	
</div><!--//wrapper-->

<footer class="footer text-center">
	<div class="container">
		<p>媒体计算与智能系统实验室</p>
		<small class="copyright">北京市海淀区中关村南大街5号北京理工大学计算机学院　100081</small>
	</div><!--//container-->
</footer>

<!-- Javascript -->          
<script type="text/javascript" src="assets/plugins/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>  
<script type="text/javascript" src="assets/plugins/back-to-top.js"></script>
<script type="text/javascript" src="assets/plugins/jquery-scrollTo/jquery.scrollTo.min.js"></script> 
<script type="text/javascript" src="assets/plugins/easy-pie-chart/dist/jquery.easypiechart.min.js"></script>
<script type="text/javascript" src="assets/plugins/imagesloaded.pkgd.min.js"></script> 
<script type="text/javascript" src="assets/plugins/isotope.pkgd.min.js"></script>  
<script type="text/javascript" src="assets/plugins/viewer.min.js"></script>

<!-- custom js -->
<script type="text/javascript" src="assets/js/main.js"></script>

<!-- Style Switcher (REMOVE ON YOUR PRODUCTION SITE) -->
<script src="assets/js/demo/style-switcher.js"></script>

<script>
	// 新闻显示
    let newsItems = document.querySelectorAll('.news-item');
    let visibleCount = 10;  // Initially show 10 items

    // Function to display only the first 10 news items
    function loadNews() {
        newsItems.forEach((item, index) => {
            if (index < visibleCount) {
                item.style.display = 'list-item';
            } else {
                item.style.display = 'none';
            }
        });
    }

    // Function to load more news items
    function loadMoreNews() {
        visibleCount += 10;  // Increase the visible count by 10
        loadNews();
    }

    // Load initial news
    loadNews();
</script>


<script>
	// 代表性期刊文章显示
	// items-wrapper 
    let journalItems = document.querySelectorAll('.portfolio-section .items-wrapper-journal .item');
    let visibleCountJournalItems = 5;  // Initially show 5 items

    // Function to display the first set of items
    function loadJournalItems() {
        journalItems.forEach((item, index) => {
            if (index < visibleCountJournalItems) {
                item.style.display = 'block'; // Show the item
            } else {
                item.style.display = 'none'; // Hide the item
            }
        });
    }

    // Function to load more items
    function loadMoreJournalItems() {
        visibleCountJournalItems += 5;  // Show 3 more items each time
        loadJournalItems();

		// Update isotope layout after adding more items
		let grid = document.querySelector('.portfolio-section .items-wrapper-journal');
    	$(grid).isotope('layout');  // 调用 Isotope 的布局更新
    }

    // Load initial items
    loadJournalItems();
</script>


<script>
	// 代表性会议论文显示
	// items-wrapper 
    let items = document.querySelectorAll('.portfolio-section .items-wrapper-paper .item');
    let visibleCountItems = 5;  // Initially show 5 items

    // Function to display the first set of items
    function loadItems() {
        items.forEach((item, index) => {
            if (index < visibleCountItems) {
                item.style.display = 'block'; // Show the item
            } else {
                item.style.display = 'none'; // Hide the item
            }
        });
    }

    // Function to load more items
    function loadMorePaperItems() {
        visibleCountItems += 5;  // Show 3 more items each time
        loadItems();

		// Update isotope layout after adding more items
		let grid = document.querySelector('.portfolio-section .items-wrapper-paper');
    	$(grid).isotope('layout');  // 调用 Isotope 的布局更新
    }

    // Load initial items
    loadItems();
</script>


<script>
	// 毕业生显示
	// items-wrapper 
    let groupItems = document.querySelectorAll('.ms-item');
    let visibleCountGroup = 1;  // Initially show 1 ms group row

    // Function to display the first set of items
    function loadGroup() {
        groupItems.forEach((groupItem, index) => {
            if (index < visibleCountGroup) {
                groupItem.style.display = 'block'; // Show the item
            } else {
                groupItem.style.display = 'none'; // Hide the item
            }
        });
    }

    // Function to load more items
    function loadMoreGroup() {
        visibleCountGroup += 2;  // Show 3 more items each time
        loadGroup();

		// Update isotope layout after adding more items
		// let grid = document.querySelector('.portfolio-section .items-wrapper');
    	// $(grid).isotope('layout');  // 调用 Isotope 的布局更新
    }

    // Load initial items
    loadGroup();
</script>



<script>
    // 词云数据（词语、大小、旋转角度、颜色、链接）
    var wordCloudData = [
      { text: "动物交互分析", size: 20, color:"#00A7BE", rotation: 90, link: "https://www.example.com/1", x:-15, y:20, isBold: false},
      { text: "计算机视觉", size: 40, color:"#00A7BE", rotation: 0, link: "https://www.example.com/1", x:0, y:0, isBold: true },
      { text: "人体动作识别", size: 25, color:"#00A7BE", rotation: 0, link: "https://www.example.com/2", x:-30, y:-80, isBold: true},
      { text: "视觉描述生成", size: 20, color:"#00A7BE", rotation: 0, link: "https://www.example.com/1", x:20, y:40, isBold: true },
      { text: "多模态视频分析理解", size: 30, color:"#00A7BE", rotation: 0, link: "https://www.example.com/3", x:-10, y:100,isBold: false},
      { text: "人工智能", size: 30, color:"#00A7BE", rotation: 90, link: "https://www.example.com/1", x:20, y:-10, isBold: false }
      // 添加更多词汇数据
    ];

    // // 定义颜色
    // var color = d3.scale.category20();
  
    // 创建词云容器
    var wordCloudContainer = d3.select("#word-cloud");
  
    // 创建词云生成器
    var cloudLayout = d3.layout.cloud()
      .size([400, 250]) // 设置词云的宽度和高度
      .words(wordCloudData)
      .padding(5)
      .rotate(function(d) { return d.rotation; }) // 旋转角度
      .fontSize(function(d) { return d.size; })
      .on("end", draw);
  
    // 生成词云 备注
    cloudLayout.start();
  
    // 绘制词云
    function draw(words) {
      wordCloudContainer
        .append("svg")
        .attr("width", cloudLayout.size()[0])
        .attr("height", cloudLayout.size()[1])
        .append("g")
        .attr("transform", "translate(" + cloudLayout.size()[0] / 2 + "," + cloudLayout.size()[1] / 2 + ")")
        .selectAll("text")
        .data(words)
        .enter()
        .append("text")
        .attr("class", "word-cloud")
        .style("font-size", function(d) { return d.size + "px"; })
        .style("fill", function(d) { return d.color; })
        .style("cursor", "pointer")
        .attr("text-anchor", "middle")
        .attr("transform", function(d) {
          return "translate(" +[d.x, d.y] + ") rotate(" + d.rotate + ")";
        })
        .text(function(d) { return d.text; })
        .on("mouseover", function(d) {
          d3.select(this)
            .transition()
            .duration(200)
            .style("font-size", function(d) { return (d.size + 10) + "px"; });
        })
        .on("mouseout", function(d) {
          d3.select(this)
            .transition()
            .duration(200)
            .style("font-size", function(d) { return d.size + "px"; });
        })
        .on("click", function(d) {
          window.open(d.link, "_blank");
        });
    }
  </script>

</body>
</html>